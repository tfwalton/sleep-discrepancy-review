---
title: 'Approaches to Measuring and Conceptualising Sleep Discrepancy: A Scoping Review'
author: "Tom Walton^1^, Melissa Ree^1^, Romola S. Bucks^1^"
date: "2023-07-18"
output:
  bookdown::html_document2:
bibliography: ["references_body.bib", "references_review.bib", "references_acti.bib"]
# csl: american-medical-association-10th-edition.csl
always_allow_html: yes
nocite: '@*'
---

```{r initial code, echo = FALSE}

################################ Initial code ##################################

# Load packages
pacman::p_load("tidyselect",
               "tidyverse",
               "magrittr",
               "stringr",
               "bookdown",
               "knitr",
               "kableExtra",
                "ggplot2",
               "english")

# Read data set into data frame
screen <- read.csv("C:/Users/tfioc/Documents/sleep-discrepancy-review/review_data.csv")

# Trim excluded studies from the data frame
screen <- filter(screen, fulltext_include=="Yes" | fulltext_include=="Second study")

#========  Functions to make inline code easier to read (enclose arguments in "")  =========

# catg counts string values equal to second arg in column name (first arg)

catg <- function(x, y, brackets = TRUE) {
  i <- which(colnames(screen) == x)
  
  if (brackets == FALSE) {
    length(which(screen[ ,i] == y))
    }
  else {
  paste0 ("(n = ",
         length(which(screen[ ,i] == y)),
         ")") %>%
         I() # print result "as is"
  }
}

# onehot finds the sum of a column defined by the argument

onehot <- function(x, brackets = TRUE) {
  i <- which(colnames(screen) == x)
  
  if (brackets == FALSE) {
    sum(screen[ ,i], na.rm=TRUE)
  }
  else {
  paste0  ("(n = ",
          sum(screen[ ,i], na.rm=TRUE),
          ")") %>%
          I() # print result "as is"
  }
}
#=================   End of functions   ===================

# Assign some screening variables
duplicates <- 3903
total_records <- 6190
```

# Abstract {#abstract}

## Study Objectives 

This scoping review examines how sleep discrepancy has been conceptualised and identifies and evaluates methods that have been used to investigate it.

## Method

We searched MEDLINE (Ovid), Embase (Ovid), PsycInfo (Ovid), CINAHL Plus, PubMed, Scopus, and Web of Science for relevant studies. Titles and abstracts, and then full text records of searched studies were screened. Methodological information was extracted including measures of self-report and objective sleep, sleep variables, discrepancy indices, handling of repeated measurements, and methods of measure comparison.

## Results

`r nrow(screen) %>% english() %>% str_to_sentence` studies were included in this review. Studies varied according to objective sleep measure; actigraphy algorithm, software, and rest interval; polysomnography setting and scoring criteria; sleep variables; self-report sleep measure; number of nights of objective recording; time frame of self-report measure; self-report sleep variable definition; sleep discrepancy derived index; presence and handling of repeated measurements; and statistical method for measure comparison.

## Conclusions

Methods of measurement and operational definitions for sleep discrepancy varied considerably across identified studies. The conceptual and theoretical implications of these methodological differences are discussed in the context of research in insomnia and other areas.

## Key words

Sleep discrepancy; sleep misperception; scoping review

# Introduction {#introduction}

Sleep is measured in two principal ways: objectively through polysomnography or actigraphy, and by self-report through questionnaires or sleep diaries. The discordance that can exist between these two forms of measurement is known as subjective-objective sleep discrepancy, or more simply, sleep discrepancy. Sleep discrepancy is a common feature of insomnia disorder, where it is also referred to as sleep misperception or paradoxical insomnia. Individuals with insomnia tend to underestimate total sleep time (TST), and overestimate sleep onset latency (SOL) and wake after sleep onset (WASO) relative to objective measures [@Baglioni2014; @edinger_1995; @means_2003].\ 

<!-- Melissa suggests mentioning SD resolution following tx of insomnia (Spina) -->

There are diverse ways to conceptualise and measure sleep discrepancy. It may be considered as a spectrum [e.g, @trajanovic_2007], ranging from positive (self-report exceeds objective) to negative (objective exceeds self-report), or as a measure of absolute sleep agreement [e.g., @baillet_2016]. Any number of sleep variables such as TST, SOL, or WASO may used to operationalise sleep discrepancy, each differing conceptually and carrying varying theoretical implications. Sleep discrepancy may even be considered beyond these sleep time-based metrics and represent discordance in self-report and objective sleep patterns [e.g., @allawati_2021], or sleep quality. Sleep discrepancy may be characterised in a sample by directly comparing self-report and objective sleep with a range of statistical techniques. Other studies may derive variables to define sleep discrepancy quantitatively to measure its relationship with other variables, for example using a difference score of self-report TST - objective TST. There appear to be a variety of ways to derive these variables each of which, again, are likely to hold varying conceptual implications. 

To date, there have been few systematic attempts to synthesise or evaluate the varied approaches to investigating sleep discrepancy. Two reviews have been conducted in this area. @Castelnovo2019 conducted a systematic review of quantitative definitions of paradoxical insomnia, an insomnia subvariant defined, in part, by the presence of sleep discrepancy. This excluded studies where sleep discrepancy was not used to form diagnostic criteria. A second review was conducted by @Rezaie2018 ---a literature review of the clinical features, aetiology, correlates, and treatment of sleep discrepancy and paradoxical insomnia. Whilst an informative discussion of research findings, this study eschewed a methodological focus and did not incorporate a systematic search, potentially underrepresenting the breadth of the literature.

Presently, it isn't clear how sleep discrepancy should best be defined and the diversity in its measurement and conceptualisation may present a challenge to theory-building for research in insomnia and other areas. A scoping review is a method of research synthesis that aims to map existing literature in a field of interest and identify types of evidence available in a given topic [@Arksey2005]. We used a scoping review strategy to examine how sleep discrepancy has been conceptualised in the literature and identify and evaluate the methods used to investigate it. A preliminary search of Medline (Ovid), the Cochrane Library, Embase (Ovid), and PsycInfo (Ovid) was conducted to identify existing or in-progress systematic or scoping reviews on the topic. Except for the two reviews mentioned above, no records were identified.

# Methods

## Protocol and registration {#protocol}

The review was conducted according to guidelines provided by the JBI scoping review methodology group [@Peters2020] and reported according to the Preferred Reporting Items for Systematic reviews and Meta-Analyses
extension for Scoping Reviews (PRISMA-ScR) Checklist [@tricco2018]. A review protocol was registered with the Open Science Framework on April 4, 2022 (doi: 10.17605/OSF.IO/BCJNQ), prior to conducting searches. Deviations from the protocol are outlined in Appendix B.

## Eligibility criteria {#item6}

Participants of all age groups and clinical populations were included in the review. To adequately map the boundaries of sleep discrepancy as a concept, we included any study that compared an objective measure of sleep (e.g., polysomnography, actigraphy) with an equivalent self-report measure of sleep (e.g., sleep diaries, questionnaires), through statistical analysis or composite index scores. For measures of self-report and objective sleep, we included traditional indices of sleep time such as TST, SOL, and WASO, in addition to measures of sleep quality, sleep patterns, or any other sleep-related experience or behaviour.

## Exclusion criteria

Studies were excluded that (i) made no direct comparisons between equivalent self-report and objective sleep measures, (ii) included informant, rather than self-report measures, (iii) were case reports or review articles, (iv) included self-report or objective measures that were not related to sleep, (v) contained no empirical data, (vi) omitted either a self-report or equivalent objective measure of sleep, (vii) were a grey literature source including theses, dissertations, and conference abstracts. No records were excluded on the basis of geographic location, cultural factors, or any other contextual feature.

## Search strategy {#item7}

The search strategy aimed to identify articles published in peer-reviewed journals and, initially, grey literature including theses, dissertations, and conference abstracts. Due to the large number of records returned by initial searches, grey literature was excluded at the full text extraction stage. The following databases were searched: MEDLINE (Ovid), Embase (Ovid), PsycInfo (Ovid), CINAHL Plus, PubMed, Scopus, Web of Science, ProQuest Theses and Dissertations, and OSF Preprints. The search strategy included keywords, index terms, and search operators adapted for each database. Searches across all databases were conducted on the 24th April 2022. The full search strategy for Embase (Ovid) is provided as an example in Table \@ref(tab:egsearch) below. See Appendix A for full search strategies for other databases.

```{r egsearch, echo = FALSE, warning = FALSE, message = FALSE}
col1 <- seq(1:7)
col2 <- c('sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actimetry/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6'
          )
col3 <- c(488, 193243, 1676, 9362, 193302, 1234, 1569)
df <- data.frame("Step" = col1, "Terms and operators" = col2, "Records" = col3)

kable(df,
      format = "html",
      col.names = c("Step","Terms and Operators", "Records"),
      caption = "Search strategy for Embase (Ovid)"
      ) %>%
  kable_styling(font_size = 11, full_width = F)
```

## Sources of evidence selection {#item9}

Records identified from searches were exported to EndNote 20 [@EndNote20] for collation and then uploaded to Rayyan [@Ouzzani2016] for deduplication and title and abstract screening. Two independent reviewers (TW and SF) screened titles and abstracts to identify studies for full-text retrieval using the inclusion criteria. Percentage of agreement between reviewers was 87.6% and conflicts were resolved via discussion. The full texts of articles passing title and abstract screening were screened independently by the first author with reasons for exclusion reported. Due to the unanticipated size of the literature, articles from sources other than peer-reviewed journals were added to exclusion criteria post-hoc.

## Charting the data {#item10}

Data extraction was performed by a single author (TW). Methodological features of included articles were selected on their potential influence on the measurement or operational definition of sleep discrepancy and included the following: objective sleep measure type/hardware, actigraphy algorithm, software, and rest interval, polysomnography setting and scoring criteria, self-report sleep measure, sleep variables (e.g., TST, WASO etc...) and definitions thereof, methods of handling repeated measurements, methods of comparing self-report and objective sleep within groups, and methods for operationalising sleep discrepancy at the construct level including the use of derived scores.

## Data items {#item11}

Extracted data items are described in the codebook available at: githublink.

## Synthesis of results {#item13}

This manuscript, including all tables and figures summarising data were generated using computationally reproducible methods from the master charting table available at (github link) [@piccolo2016; @lindsay2023].

<!-- now describe how you organised the studies categories-->
<!-- Tom: I have this in the codebook, I think that there is too much information to include in the text of the review -->

# Results {#item14}

The initial search of databases returned `r total_records` from which `r duplicates` duplicate articles were removed. Details of the review process from article identification, screening, and selection are available in the PRISMA flowchart depicted in \@ref(fig:PRISMA) below.

```{r PRISMA, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "PRISMA flowchart"}
###############################################################################
############################# PRISMA flowchart ################################
#-----------------------------------------------------------------------------#

# Records identified
Embase <- 1569
PsycInfo <- 471
MEDLINE <- 875
Pubmed <- 761
CINAHL <- 310
SCOPUS <- 826
WOS <- 1288
Proquest <- 90

duplicates <- 3903
screened <- 2290
excluded <- 1640
sought <- 650
assessed <- 648
ftexcluded <- 121

excluded1 <- 42       # No direct comparisons between equivalent parameters
excluded2 <- 36       # Informant report only
excluded3 <- 7        # Duplicate
excluded4 <- 9        # Case report
excluded5 <- 1        # Self-report or objective measures not related to sleep
excluded6 <- 5        # Review article
excluded7 <- 10       # Not empirical study
excluded8 <- 19       # Article in language other than English
excluded9 <- 1        # Either self-report or objective measure not included
excluded10 <- 270     # Grey literature source

total <- 245

#------------------------------------------------------------------------------#    
###################   Prepare vectors for GraphViz   ###########################
#------------------------------------------------------------------------------#      

titles <- c("Records identified from",
            "Duplicate records removed",
            "Records screened",
            "Records excluded",
            "Reports sought for retrieval",
            "Reports assessed for eligibility",
            "Reports excluded",
            "Total studies included in review"
)

list_identified <- c(paste0("Embase ","(n = ", Embase, ")"),
                     paste0("PsycInfo ","(n = ", PsycInfo, ")"),
                     paste0("MEDLINE ","(n = ", MEDLINE, ")"),
                     paste0("Pubmed ","(n = ", Pubmed, ")"),
                     paste0("CINAHL Plus","(n = ", CINAHL, ")"),
                     paste0("SCOPUS ","(n = ", SCOPUS, ")"),
                     paste0("Web of Science ","(n = ", WOS, ")"),
                     paste0("Proquest Theses and Dissertations Global ","(n = ", Proquest, ")")
)

list_duplicates <- c(paste0("(n = ", duplicates, ")"))
list_screened <- c(paste0("(n = ", screened, ")"))
list_excluded <- c(paste0("(n = ", excluded, ")"))
list_sought <- c(paste0("(n = ", sought, ")"))
list_assessed <- c(paste0("(n = ", assessed, ")"))

list_ftexcluded <- c(paste0("(n = ", ftexcluded, ")"),
                     paste0("No direct comparisons between equivalent parameters ","(n = ", excluded1, ")"),
                     paste0("Informant report only ","(n = ", excluded2, ")"),
                     paste0("Duplicate (missed at title and abstract screening; n = ", excluded3, ")"),
                     paste0("Case report ","(n = ", excluded4, ")"),
                     paste0("Self-report or objective measures not related to sleep ","(n = ", excluded5, ")"),
                     paste0("Review article ","(n = ", excluded6, ")"),
                     paste0("Not empirical study ","(n = ", excluded7, ")"),
                     paste0("Article in language other than English ","(n = ", excluded8, ")"),
                     paste0("Either self-report or objective measure not included ","(n = ", excluded9, ")"),
                     paste0("Grey literature source ","(n = ", excluded10, ")")
)

list_total <- c(paste0("(n = ", total, ")"))

#------------------------------------------------------------------------------#    
######################     Generate flow chart     #############################
#------------------------------------------------------------------------------# 

pacman::p_load("DiagrammeR", "tidyverse")

grViz("
digraph { 


graph[layout = dot, rankdir = TB]
node[shape = box, fontsize = 12, width = 4];

      {rank=same identified duplicates}
      {rank=same screened excluded}
      {rank=same assessed ftexcluded}

        identified [label = '@@1-1\\l     @@2-1\\l     @@2-2\\l     @@2-3\\l     @@2-4\\l     @@2-5\\l     @@2-6\\l     @@2-7\\l     @@2-8\\l']
        duplicates [label = '@@1-2 @@3-1']
        screened [label = '@@1-3 @@4-1']
        excluded [label = '@@1-4 @@5-1']
        sought [label = '@@1-5 @@6-1']
        assessed [label = '@@1-6 @@7-1']
        ftexcluded [label = '@@1-7 @@8-1\\l      @@8-2\\l     @@8-3\\l     @@8-4\\l     @@8-5\\l     @@8-6\\l     @@8-7\\l     @@8-8\\l     @@8-9\\l     @@8-10\\l     @@8-11\\l']
        total [label = '@@1-8 @@9-1']

identified -> duplicates
identified -> screened
screened -> excluded
screened -> sought
sought -> assessed
assessed -> ftexcluded
assessed -> total


}
    [1]: titles
    [2]: list_identified
    [3]: list_duplicates
    [4]: list_screened
    [5]: list_excluded
    [6]: list_sought
    [7]: list_assessed
    [8]: list_ftexcluded
    [9]: list_total
", height = "100%")
```

## Article characteristics {#item15}
For a full list of article characteristics for which data were charted, see the master table available at: github link. A total of `r nrow(screen)` studies were identified from `r catg("fulltext_include", "Yes")` records, with `r catg("fulltext_include", "Second study")` records reporting two studies or experiments within a single text. Records spanned `r unique(c(screen$country, screen$country2)) %>% length()` countries, with the majority originating from the USA (n = `r length(which(screen$country == "USA" | screen$country2 == "USA"))`). A full list of countries is available in the supplemental materials.

```{r sample sizes, echo = FALSE, warning = FALSE, message = FALSE}
sample_size <- as.numeric(screen$sample_size)
```

Sample sizes for studies ranged from `r min(sample_size, na.rm=TRUE)` to `r max(sample_size, na.rm=TRUE)` (median = `r median(sample_size, na.rm=TRUE)`, IQR = `r IQR(sample_size, na.rm=TRUE)`). Most studies included both sexes in their samples (n = `r length(which(screen$sample_sex == ""))`), whereas `r  length(which(screen$sample_sex == "men"))` and `r length(which(screen$sample_sex == "women"))` comprised only males or females, respectively. Most studies contained samples of adults of all ages `r length(which(screen$sample_age == "adults"))`. Others reported specific age groups: older adults (n = `r length(which(screen$sample_age == "older adults"))`), younger adults (n = `r length(which(screen$sample_age == "young adults"))`), adolescents (n = `r length(which(screen$sample_age == "adolescents"))`), and children (n = `r length(which(screen$sample_age == "children"))`). Sample characteristics for studies are included in Figure \@ref(fig:samplechar).
```{r samplechar, results = 'asis', collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Sample characteristics", fig.height = 8}

# generate a frequency table for the three columnns
samplechar <- c(screen$sample_clinical, screen$sample_clinical2, screen$sample_clinical3)

# remove the row that counted blank spaces
samplechar <- samplechar[-which(samplechar=="")] %>% as.data.frame()

# assign a name to the single column
colnames(samplechar) <- "sample"

# Generate graph
ggplot(data = samplechar, aes(x = fct_infreq(sample) %>% fct_rev())) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Sample characteristics", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
  ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
  ) +
  coord_flip()

```

## Methodological features {#resultsandsynthesis}

### Measures of objective sleep

Objective methods of recording sleep formed two major groups: EEG-based methods (n = `r sum(screen$obj_EEG, na.rm=TRUE)`) and movement-based methods (n = `r sum(screen$obj_movement, na.rm=TRUE)`). All movement-based methods involved tri-axial accelerometry through actigraphs or similar devices. PSG was the predominant EEG-based method (n = `r sum(screen$obj_PSG, na.rm=TRUE)`), however a handful of studies used EEG alone, in either single channel (n = `r length(which(screen$obj_EEG_other == "single channel EEG"))`), standard (n = `r length(which(screen$obj_EEG_other == "EEG"))`), or high definition formats (n = `r length(which(screen$obj_EEG_other == "HD-EEG"))`). A single study used a method of sleep recording that involved recording verbal responses from participants elicited by soft tones played at intervals throughout the night [@espie_1989].

#### Polysomnography

Methodological features charted for PSG included scoring criteria, setting, and recording period. Scoring criteria for PSG were split between American Academy of Sleep Medicine (AASM; n = `r length(which(screen$psg_scoring == "AASM"))`) and Rechtschaffen & Kales (R&K; n = `r length(which(screen$psg_scoring == "R&K"))`) guidelines. @rogers_reliability_1993 used an automated system for sleep staging, the SS90-III Sleep Stager System (Oxford Medicals, Oxford). @vanable_sleep_2000 used @mendelson2012human's guidelines in addition to R&K. @edinger_1995 used combined audio and visual criteria for sleep staging [@erwin1989]. A total of `r length(which(screen$psg_scoring == "not reported"))` studies did not report scoring criteria. In terms of setting, PSG was more frequently conducted in a laboratory (n = `r length(which(screen$psg_setting == "in-lab")) + length(which(screen$psg_setting == "in-lab, home-based"))`) than at home (n = `r length(which(screen$psg_setting == "home-based")) + length(which(screen$psg_setting == "in-lab, home-based"))`). Other environments included a truck-berth (n = `r length(which(screen$psg_setting == "truck-berth"))`), fMRI (n = `r length(which(screen$psg_setting == "fMRI"))`) and an airline rest facility (n = `r length(which(screen$psg_setting == "rest facility"))`). A total of `r length(which(screen$psg_setting == "not reported"))` studies did not report scoring criteria. Recording periods were predominantly nocturnal (n = `r length(which(screen$psg_period == "nocturnal")) + length(which(screen$psg_period == "nocturnal; MSLT"))`), but also included daytime naps (n = `r length(which(screen$psg_period == "MSLT")) + length(which(screen$psg_period == "nocturnal; MSLT")) + length(which(screen$psg_period == "daytime nap"))`), and other sleep periods (n = `r  length(which(screen$psg_period == "24-hour")) + length(which(screen$psg_period == "repeated naps across 28-hour period")) + length(which(screen$psg_period == "nocturnal nap")) + length(which(screen$psg_period == "in-flight / layover"))`).

#### Actigraphy

We recorded features of actigraphy that included device name, scoring algorithm, software, and rest interval definition. See supplemental materials for descriptions of actigraphy devices. Actigraphy scoring algorithms are responsible for determining wakefulness and sleep from accelerometer-derived motor activity. Use of scoring algorithms varied across studies and are listed below in Figure \@ref(fig:algorithms).

```{r algorithms, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Actigraphy and accelerometer algorithms"}

graph <- screen %>% select("acti_algorithm":"acti_algorithm3")

# Function to replace cell values containing Actiware with Actiware

collapseActiware <- function(x) {
  ifelse(grepl("Actiware", x), "Actiware", x)
}

# Apply function to data frame
graph <- apply(graph, c(1,2), collapseActiware)

# Collapse data frame into single vector, generate frequency table, then data frame
graph <- c(graph[,1], graph[,2], graph[,3]) %>% unlist() %>% table() %>% as.data.frame(stringsAsFactors = FALSE)

# Replace column names
colnames(graph) <- c("algo", "freq")

algo_citations <- read.csv("C:/Users/tfioc/Documents/sleep-discrepancy-review/algorithm_citations.csv")

# Search the table for a citation that matches the algorithm and paste it into each cell
for (x in graph[ ,1]) {
  i <- which(graph[ ,1] == x)
  ref <- which(algo_citations[ ,1] == x)
  graph[i,1] <- paste(graph[i,1], algo_citations[ref,2])
}

# sort ascending by frequency
graph <- graph[order(graph[ ,2], decreasing = FALSE), ]

# rename "not reported" and place last
row_num <- which(graph[ ,1] == "not reported ")
noreport <- graph[row_num, ]
noreport[1,1] <- "Algorithm not reported"
graph <- graph[-row_num, ]
graph <- rbind(noreport, graph)

# Generate graph
ggplot(data = graph, mapping = aes(x = algo, y = freq)) +
  geom_bar(stat="identity") +
  labs(x = "Algorithm", y = "Number of studies") +
  scale_x_discrete(limits=unique(graph$algo)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=freq),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,60)) +
  coord_flip()

```

Studies using Actiware algorithms varied in their selection of thresholds for scoring wakefulness. These are depicted in Figure \@ref(fig:actiware) below.

```{r actiware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Actiware algorithm threshold settings", fig.height = 3}
acti <- c(screen$acti_algorithm, screen$acti_algorithm2, screen$acti_algorithm3) %>% as.data.frame()

acti <- acti[apply(acti, 1, function(x) grepl("Actiware", x)), ] %>% as.data.frame()

labels = c("All thresholds (Low, Medium, High)", "80 activity counts (High)", "40 activity counts (Medium)", "20 activity counts (Low)", "10 activity counts (Low)", "Actiware wake threshold not reported")

# convert strings to factors
acti[ ,1] <- factor(acti[ ,1], levels = c("Actiware (Low, Medium, High)", "Actiware High (80)", "Actiware Medium (40)", "Actiware Low (20)", "Actiware Low (10)", "Actiware (not reported)"), labels = labels)

colnames(acti) <- "threshold"

ggplot(data = acti, aes(reorder(threshold, -as.integer(threshold)))) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Actiware threshold", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
    ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
    ) +
  coord_flip()
```

The rest interval in actigraphy is the period of time where activity is assessed for sleep and is usually intended to coincide with the time the wearer is in bed, attempting to sleep. Information used to define rest intervals varied across reviewed studies and included, singly or in combination, are depicted below in Figure \@ref(fig:intervals).

```{r intervals, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Methods for defining rest intervals in actigraphy"}
#----------------   one-hot encoded rest interval data   ----------------------|

interval <- c("interval_marker",
              "interval_diary",
              "interval_light",
              "interval_activity",
              "interval_external",
              "interval_auto",
              "interval_noreport"
) %>% 
  as.data.frame()
interval["studies"] <- vector()

q = 0

for (x in interval[ ,1]) {
  ref <- which(colnames(screen) == x)
  i <- sum(screen[ref], na.rm = TRUE)
  q <- q + 1
  interval[q ,2] <- i
}

interval[ ,1] <- c("Event marker press",
                   "Sleep diary",
                   "Light sensor",
                   "Manual judgements of activity",
                   "External parameters such as set bed and rise times",
                   "Automatic scoring",
                   "Rest interval not reported")

colnames(interval) <- c("interval", "studies")
#---------------   standard encoding in the "other" column   ------------------|

other <- unique(screen$interval_other)
other <- other[-1] # remove the NA
other <- as.data.frame(other)
other["studies"] <- vector() # add an empty vector

q = 0

for (x in other[ ,1]) {
  i <- length(which(screen$interval_other == x))
  q <- q + 1
  other[q ,2] <- i
}

colnames(other) <- c("interval", "studies")
#------------------------------------------------------------------------------|

interval <- rbind(interval, other)

# sort ascending by frequency
interval <- interval[order(interval[ ,2], decreasing = FALSE), ]

# place "not reported" place last
row_num <- which(interval[ ,1] == "Rest interval not reported")
noreport <- interval[row_num, ]
interval <- interval[-row_num, ]
interval <- rbind(noreport, interval)

# Generate graph
ggplot(data = interval, mapping = aes(x = interval, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "Rest interval", y = "Number of studies") +
  scale_x_discrete(limits=unique(interval$interval)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,70)) +
  coord_flip()
```

The precise combinations or orders of priority of methods in each study varied markedly. See master data file (github link) for qualitative descriptions of rest interval approaches across reviewed studies. Discrepancies queried indicates that discrepant sleep diary and actigraphy bed and wake times were queried directly with participants and adjusted following discussion.

### Measures of self-report sleep

Nine types of self-report sleep measure were identified: sleep diaries such as the consensus sleep diary [@Carney2012], where data are entered in a numerical format `r onehot("subj_diary")`; graphical sleep diaries (also known as raster plots), where responses are drawn on scales comprising discrete blocks of time `r onehot("subj_graphdiary")`; morning questionnaires, single-night estimates of self-report sleep typically administered following PSG `r onehot("subj_morningq")`; habitual sleep questionnaires such as the Pittsburgh Sleep Quality Index [PSQI\; @buysse1989], where respondents provide information on their usual sleep over a period of weeks `r onehot("subj_otherhabitual")`; morning questionnaires, where participants are queried directly by experimenters about their sleep `r onehot("subj_postnapq")`; graphical post-nap questionnaires that require graphical responses such as shading blocks of time `r onehot("subj_postnapgraphq")`; and post-wake interviews where participants are queried about their sleep directly following natural or induced awakenings `r onehot("subj_morninginterview")`. The specific self-report sleep questionnaire used in each study was recorded when this information was available. See supplemental materials for a qualitative overview of sleep questionnaires. We also recorded whether self-report sleep measures aimed to capture *habitual sleep*, an individual's typical sleep over a period of weeks to a month, or sleep occurring night-by-night or sleep episode-by-sleep episode at the same time as objective measures, referred to here as *episodic* sleep. In the present review, `r catg("subj_habitual_desc", "habitual", brackets=FALSE)` studies measured habitual sleep, `r catg("subj_habitual_desc", "matched", brackets = FALSE)` studies measured episodic sleep, and `r catg("subj_habitual_desc", "habitual, matched", brackets = FALSE)` measured both.

## Sleep variables

A range of variables were used to measure sleep discrepancy. These are depicted below in Table \@ref(tab:variables).\

```{r variables, echo = FALSE}
# Read template table from folder
sleep_variables <- read.csv("C:/Users/tfioc/Documents/sleep-discrepancy-review/sleep_variables.csv")

# Assign 0 to index variable for upcoming loop
q = 0

# Generate empty vector to match length of template table
vec <- vector(length = length(sleep_variables[ ,1]))

# For each variable name listed in the template table...
# search the main dataset for the matching variable
# return the column sum
# store it in the empty vector

for (x in sleep_variables[ ,1]) {
  i <- which(colnames(screen) == x)
  q <- q + 1
  vec[q] <- sum(screen[ ,i], na.rm = TRUE)
}

# Add new vector to existing template table
sleep_variables <- cbind(sleep_variables, vec)

# Remove the column containing the variable names
sleep_variables<- sleep_variables[ ,-1]

# Rename the columns to something nice
colnames(sleep_variables) <- c("Variable name", "Abbreviation", "Calculation", "Equivalent terms", "Number of studies")

# Add superscript to TWAK for footnote
sleep_variables[which(sleep_variables[ ,2] == "TWAK"),5] <- paste0(sleep_variables[which(sleep_variables[ ,2] == "TWAK"),5], footnote_marker_symbol(1))

# Generate table
kable(sleep_variables,
      caption = "Sleep variables used for operationalising sleep discrepancy",
      escape = FALSE,
) %>%
  kable_styling(font_size = 11, full_width = F) %>% footnote(general = "Sleep wake agreement (one possible objective sleep state) involved measuring at one or multiple instances whether a participant's reported sleep state matched the objective sleep state upon which the query was conditional (e.g., participants were only queried during objectively-confirmed sleep). On the other hand, sleep wake agreement (two possible sleep states) involved measuring at one or multiple instances whether a participant's reported sleep state matched an objective sleep state that was allowed to vary independent of the query (e.g., participants were queried at a certain time point irrespective of sleep state). The former approach produces a binary outcome whereas the latter produces a confusion matrix.", symbol = "TWAK was not used to define sleep discrepancy directly by any of the included studies but is included in the table for clarity")

```
Discrepancy was also investigated in variables outside of conventional sleep time parameters. @allawati_2021 compared self-report and actigraphic measures of sleep patterns including monophasic, biphasic dawn, biphasic siesta, and polyphasic. @lockley_comparison_1999, @dautovich_subjective_2008, @hanisch_sleep_2011, and @nguyen-michel_underperception_2015 reported discrepancy for naps specifically, including variables such as number of naps, number of days napped, mean duration of naps, and total nap time. @baek_2020 and @chan_sleep_2018 compared self-report and actigraphic assessments of variability in TST and other sleep parameters. @thun_actigraphic_2012 compared self-report and actigraphic measures of morningness-eveningness. Finally, @mcintyre_2016 investigated subjective-objective discrepancy across a range of sleep behaviours including position at sleep onset, position at wake, number of positional changes, and the presence of leg twitches or jerks.

### Self-report sleep variable definitions

Calculation of self-report sleep variables total sleep time (TST), wake after sleep onset (WASO), sleep efficiency (SE), and time in bed (TIB) varied across studies. Three types of self-report TST were observed: TST queried directly (e.g., "how many minutes did you sleep last night"; n = `r sum(screen$subj_tst_directq, na.rm=TRUE)`); TST calculated from other parameters such as TIB, SOL, and WASO (n = `r sum(screen$subj_tst_calc, na.rm=TRUE)`); and TST calculated from graphical responses (n = `r sum(screen$subj_tst_visual, na.rm=TRUE)`). Definitions for WASO included direct query (n = `r length(which(screen$subj_waso_t == "direct question"))`), calculation from numerical or graphical responses (n = `r length(which(screen$subj_waso_t == "calculated")) + length(which(screen$subj_waso_t == "visual"))`), or the definition was not reported (n = `r length(which(screen$subj_waso_t == "not reported"))`). Definitions for self-report TIB included RT-LO `r catg("subj_tib", "LO-RT")`, FA-LO `r catg("subj_tib", "LO-FA")`, TST + WASO + SOL `r catg("subj_tib", "TST+WASO+SOL")` or definition was not reported `r catg("subj_tib", "not reported")`. SE was almost unanimously calculated as TST/TIB\*100 , although varying definitions for the TST and TIB components affect this outcome. One study [@neu_sleep_2007] used two definitions of SE, one comprising TST/TIB and the other TST/sleep period time (SPT).

### Objective sleep variable definitions

Definitions of objective TST, SOL, and number of awakenings differed across studies. @sinclair_2014, in addition to providing a standard definition for TST, measured TST across a 24-hour period, such that time spent asleep outside the usual nocturnal period (i.e., naps) contributed to this measurement. Objective definitions for SOL varied and these are depicted in Figure \@ref(fig:SOL) below.\

```{r SOL, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.cap = "Definitions of objective sleep onset latency"}
#-------------------------------- SOL Bar Plot --------------------------------|

# SOL definitions

SOL <- unique(c(screen$obj_SOL_t,
                screen$obj_SOL_t2,
                screen$obj_SOL_t3,
                screen$obj_SOL_t4)
)
# delete element containing NA
SOL <- SOL[-which(SOL=="")]

# coerce into data frame
SOL <- as.data.frame(SOL)

# add empty vector for frequency
SOL["studies"] <- vector() # add an empty vector

q = 0

for (x in SOL[ ,1]) {
  i <- length(which(screen$obj_SOL_t == x | 
                      screen$obj_SOL_t2 == x |
                      screen$obj_SOL_t3 == x |
                      screen$obj_SOL_t4 == x))
  q <- q + 1
  SOL[q ,2] <- i
}

# capitalise first letter of each row
SOL$SOL <- paste0(toupper(substring(SOL$SOL,1,1)), substring(SOL$SOL,2,last = 1000L))

# sort ascending by frequency
SOL <- SOL[order(SOL[ ,2], decreasing = FALSE), ]

# rename not reported and bring to top of data frame
row_num <- which(SOL[ ,1] == "Not reported")
noreport <- SOL[row_num, ]
noreport[1,1] <- "SOL definition not reported"
SOL <- SOL[-row_num, ]
SOL <- rbind(noreport, SOL)

level_order <- c(
  "Actigraphy-defined",
  "First epoch of any sleep stage",
  "First 3 consecutive epochs of stage 1 or first epoch of any other sleep (R&K)",
  "First epoch Stage 2",
  "First 20 consecutive epochs any stage of sleep (LPS)",
  "First sleep spindle",
  "First epoch Stage 1",
  "First epoch SWS",
  "First 3 consecutive epochs of sleep",  
  "First 2 consecutive epochs of Stage 2",
  "First 10 consecutive epochs Stage 2",
  "First Stage 2 interrupted by no more than 4 epochs of wake or Stage 1 within 20 epochs",
  "First 20 epochs of sleep containing no more than 4 epochs of wake time, Stage 1 sleep, or movement time",
  "First 20 epochs of Stage 2 or SWS without intervening period of >4 epochs Stage 1 or wakefulness",
  "Video observation",
  "Parameter varied in model",
  "SOL definition not reported"
) %>% rev()

# Generate graph
ggplot(data = SOL, mapping = aes(x = SOL, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "SOL definition", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,80)) +
  scale_x_discrete(limits=level_order) +
  coord_flip()

```

Most studies used standard PSG or actigraphy criteria for defining objective number of awakenings (i.e., a single epoch of wakefulness). A single exception was @lewis_1969, who stipulated that a period last over a minute to count as an awakening. @neu_sleep_2007 used the same definitions for objective SE as they did for SE. 

### Sleep quality

Sleep quality discrepancy was measured by `r onehot("sleep_quality_measured", brackets=FALSE)` studies using (on the self-report side) sleep quality ratings `r catg("subj_sleep_sq_class", "index")`, PSQI total scores `r catg("subj_sleep_sq_class", "PSQI scores")`, sleep quality factor scores `r catg("subj_sleep_sq_class", "factor score")`, sleep depth ratings `r catg("subj_sleep_sq_class", "sleep depth rating")`, or sleep quality composite scores `r catg("subj_sleep_sq_class", "composite score")`. On the objective side, sleep quality measures included SE `r  catg("obj_sq_equiv_class", "SE")`, factor scores from sleep variables `r catg("obj_sq_equiv_class", "factor score")`, sleep architectural variables `r catg("obj_sq_equiv_class", "SE")`, N3 sleep quantity `r catg("obj_sq_equiv_class", "N3 sleep")`, TWT `r catg("obj_sq_equiv_class", "TWT")`, and a composite variable formed from SOL, WASO, and SE `r catg("obj_sq_equiv_class", "composite variable")`. Although approaches varied substantially, the most common combination of sleep quality measures was a sleep quality rating and SE.

<!-- Not only was there marked variability in the methods used to measure objective and subjective sleep variables and in which sleep variables were used to calculate sleep discrepancy outcomes, there was also marked variability in how sleep discrepancy was operationalised using those variables, including deriving scores for each individual, and group level analyses. -->

## Method of handling repeated measurements

Sleep data often involves repeated measurements of the same individual. Actigraphy and sleep diaries usually involve data collection across 7 to 14 days and multiple consecutive nights of PSG are sometimes recorded. The most common methods for handling repeated measures included calculating mean values across multiple instances of recording `r onehot("rm_mvalues")`, pooling data across multiple instances of recording `r onehot("rm_pool")`, using repeated measures ANOVA for analyses `r onehot("rm_rmANOVA")`, calculating mean derived score values across multiple instances of recording `r onehot("rm_mindices")`, using linear mixed models for analyses `r onehot("rm_lmm")`, and conducting analyses separately for each instance of recording `r onehot("rm_separate")`. A total of `r onehot("rm_singlenight")` studies included only a single instance of recording where no method of dealing with repeated measures was necessary. Less common methods included taking modal values [@allawati_2021] or median values [@bianchi_sleep_2012; @lubas_concordance_2022] of multiple instances of recording, calculating the standard deviation of derived index across multiple instances of recording [@kay_variability_2013], using generalised estimating equations [@lauderdale_2008], and using structural equation modelling [@friedmann_2022]. Mean values were a common way of handling repeated measurements for actigraphy studies (n = `r ifelse(screen$obj_movement == screen$rm_mvalues, 1, NA) %>% sum(na.rm = TRUE)`) and to a lesser extent PSG (n = `r ifelse(screen$obj_PSG == screen$rm_mvalues & is.na(screen$obj_movement)==TRUE & is.na(screen$obj_other)==TRUE, 1, NA) %>% sum(na.rm = TRUE)`).

Some studies measuring naturalistic sleep in the home environment took day of week into consideration for analyses. A total of `r catg("weekend", "weighted average", brackets = FALSE) + catg("weekend2", "weighted average", brackets = FALSE)` studies calculated a weighted average for sleep variables equal to 5/7* (mean weekday sleep) + 2/7* (mean weekend sleep), and `r catg("weekend", "split", brackets = FALSE) + catg("weekend2", "split", brackets = FALSE)` performed analyses for weeknights and weekends separately.

## Direct comparisons of self-report and objective sleep

A total of `r onehot("aim_agreement", brackets=FALSE)` studies measured sleep discrepancy at the group level by directly comparing self-report and objective sleep. Methods for achieving this varied and are depicted below in \@ref(fig:group)

```{r group, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Statistical methods for comparing self-report and objective sleep"}

group_variables <- read.csv("C:/Users/tfioc/Documents/sleep-discrepancy-review/group_variables.csv")

# Assign 0 to index variable for upcoming loop
q = 0

for (x in group_variables[ ,1]) {
  i <- which(colnames(screen) == x)
  q <- q + 1
  group_variables[q, 3] <- sum(screen[ ,i], na.rm = TRUE)
}

group_variables$variable_name <- factor(group_variables$variable_name, levels = group_variables$variable_name)

# order ascending
group_variables <- group_variables[order(group_variables[ ,3], decreasing = FALSE), ]

# rename not reported and bring to top of data frame
row_num <- which(group_variables[ ,2] == "Other direct comparison (described below)")
other <- group_variables[row_num, ]
group_variables <- group_variables[-row_num, ]
group_variables <- rbind(other, group_variables)

ggplot(data = group_variables, aes(x = variable_name, y = studies)) +
  geom_bar(stat="identity", position="dodge") +
  labs(x = "Methods for direct sleep comparisons", y = "Number of studies") +
  theme(legend.position = "none") +
  scale_fill_grey() +
  scale_y_continuous(limit=c(0,110)) +
  scale_x_discrete(limits=unique(group_variables$variable_name)) +  # This keeps the order of the data frame
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.25) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  )+
  coord_flip()

```
Note, Bland Altman analyses include Bland Altman plots and the reporting of 95% limits of agreement [see: @blandaltman1999]. Pitman's test (also known as the Pitman-Morgan test) is a test of differences of variances between dependent samples [@pitman1939; @morgan1939] and was used to compare the variability of self-report and objective sleep. 
1-sample t-tests of difference scores are equivalent to paired t-tests but are included separately in the figure to reflect differences in reporting. Classification performance measures include percentage agreement, accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). Formulae used for the intra-class correlation coefficient varied across studies. Spearman correlations and Wilcoxon Signed Rank Tests were often used to handle the skew of variables such as SOL and WASO. 

Other methods included the delta coefficient [@girschik_2012], partial correlation and factor analysis [@regestein_2004], errors-in-variables regression [@lauderdale_2008], repeated measures correlation [@gibson_2023], non-parametric limits of agreement [@thurman_2018], survival agreement [@guedes_2016], latent correlations for testing associations at within-subjects and between-subjects level [@fengsvetnik_2018], and structural equation modelling [@friedmann_2022].

## Methods for investigating the relationship of sleep discrepancy with other variables

A total of `r onehot("aim_construct", brackets=FALSE)` studies aimed to investigate the relationship of sleep discrepancy with other variables of interest. Most studies achieved this by operationalising sleep discrepancy on the individual level through the calculation of a derived index.

### Derived indices

Approximately half `r onehot("index_present")` of included studies calculated a derived index (e.g., self-report TST - objective TST) to operationalise sleep discrepancy. Some studies used indices directly in statistical analyses `r catg("index_groups", "0")` whilst others used indices to divide samples into groups (n =`r length(which(screen$index_groups == "binary")) + length(which(screen$index_groups == "trichotomy"))`) either dichotomising `r catg("index_groups", "binary")` or trichotomising `r catg("index_groups", "trichotomy")` derived score values. Methods for deriving indices varied across studies and can be broadly categorised into four groups: arithmetic difference scores, where one measure is simply subtracted from the other (e.g., sTST-oTST); absolute difference scores, composed of the absolute value of algebraic difference scores (e.g., \|sTST--oTST\|); ratio scores, when one measure is divided by the other (e.g., sTST/oTST); and combination scores that incorporate both subtraction and division of component measures (e.g., oTST-sTST/oTST). A list of indices including the number of studies that used them are provided in Figure \@ref(fig:derived) below.

```{r derived, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Derived indices used for operationalising sleep discrepancy", fig.height = 8, fig.width = 9}

#------------------------   Derived indices plot   ----------------------------|

codebook <- read.csv("C:/Users/tfioc/Documents/sleep-discrepancy-review/derived_variables.csv")

derived <- c(screen$index1,
             screen$index2,
             screen$index3,
             screen$index4,
             screen$index5,
             screen$index6,
             screen$index7,
             screen$index8) %>% as.factor() 
derived <- derived[-which(derived=="")] %>% as.data.frame()

# ----   Find variable information from variable codes  ----
q = 0 # Assign 0 to index variable for upcoming loop

for (x in derived[ ,1]) {
  i <- codebook[which(codebook[ ,1] == x), 2:4]
  q <- q + 1
  derived[q,2:4] <- i
}

# store order for facets
facet_order <- c("Arithmetic difference scores",
                 "Absolute difference scores",
                 "Ratio scores",
                 "Combination scores",
                 "")

# convert strings to factors (necessary for facet_grid)
derived[ ,2] <- factor(derived[ ,2], levels = facet_order)

ggplot(data = derived, aes(x = reorder(variable_name, variable_name, function(x)length(x)))) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = " ", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
    ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
    ) +
  facet_grid(rows = vars(variable_group),
             scales = "free_y",
             space = "free_y",
             switch = "y",
             labeller = labeller(variable_group = label_wrap_gen(width = 10))
  ) +
  coord_flip()

```

Overall, the sleep variables TST, SOL, and WASO represented the substantial majority of derived indices. Arithmetic difference scores were the most common derived index and with these objective sleep was subtracted from self-report sleep considerably more often than vice-versa. By contrast, ratio scores did not differ in directionality, and all that were recorded featured self-report sleep as the numerator and objective sleep as the denominator. Absolute differences are unique amongst derived indices for operationalising negative sleep discrepancy as equal to positive sleep discrepancy. With the relatively few absolute difference scores noted here it appears that the literature has mostly conceived of sleep discrepancy as a directional concept. All the combination scores identified followed the general format of an arithmetic difference score divided by a component of the difference. This method of deriving scores was first devised by @manconi_measuring_2010. Their index was named the misperception index (MI) in its first iteration, is defined as oTST-sTST)/oTST, and was the most common combination score we identified. The MI was constructed to reproduce the bimodal distribution observed with OSE in insomnia patients whilst providing a strong correspondence to the difference score oTST-sTST. Possible values for the MI range from $-\infty$ (extreme over-estimation) to +1 (extreme underestimation), although @manconi_measuring_2010 recommends trimming the lower limit to -1. The principle of dividing an existing difference score by the objective component has since been extended by successive authors to other sleep variables (see the "Combination scores" facet in Figure \@ref(fig:derived) above).

A handful of more atypical derived scores were identified. @jackowska_psychosocial_2011 created a sleep quality discrepancy index by subtracting a z-transformed self-report sleep quality rating from z-transformed objective SE. @kay_variability_2013 derived a nightly variability index for sSOL-oSOL and sWASO-oWASO by dividing intra-individual standard deviations by the sample-wise standard deviation for each variable. @mendelson_1986 divided self-report sleep following experimental awakenings by objective sleep following experimental awakenings. @winer_tau_2021 derived a difference score from subtracting composite scores composed of the average of z scores of TST, SE, and sleep fragmentation (number of awakenings/SPT\*100) from z-transformed PSQI total scores.

### Other methods for operationalising sleep discrepancy

A number of other ways to characterise the relationship of sleep discrepancy with other variables of interest were identified. `r onehot("construct_interaction", brackets=FALSE)` studies operationalised sleep discrepancy using an interaction term within an ANOVA or other linear model such that the other variable(s) of interest was/were instantiated as the moderator of the relationship between self-report and objective sleep. `r onehot("construct_agreeinstat", brackets=FALSE)` studies used percentage agreement for sleep or other classification performance metrics in subsequent statistical analyses with other variables. `r onehot("construct_corrdiff", brackets=FALSE)` studies tested the differences between correlations amongst self-report and objective sleep between groups with bootstrapped confidence intervals [@jackson_2018, @jackson_2020], or the Fisher transformation [@defrancesco_2021]. `r onehot("construct_modelling", brackets=FALSE)` studies operationalised sleep discrepancy with the Sleep Fragment Perception Index (SFPI), an index that exploits the fact that longer sleep fragments are more likely to be identified as sleep by individuals than shorter fragments [@hermans_modeling_2020]. The SPFI is a parameter modelled to assume the shortest length of objective sleep that is perceived as subjective sleep. For the SFPI, a higher value corresponds to a longer sleep fragment necessary for subjective awareness of sleep and hence greater sleep discrepancy.

## Miscellaneous methodological features

Lastly, we recorded some other methodological features of studies that appeared pertinent to the study of sleep discrepancy. `r onehot("misc_cbti", brackets = FALSE)` studies investigated sleep discrepancy during, as a predictor of response to, or as an outcome of, cognitive behaviour therapy for insomnia (CBT-I). `r onehot("misc_exp_awakenings", brackets = FALSE)` studies used an experimental awakening paradigm where participants were monitored in-lab and woken by sound probes or technician interventions.

# Discussion {#item19}

This systematically reviewed concepts and methods in the area of sleep discrepancy research. We found considerable methodological diversity across a vast literature and identified important conceptual and methodological issues in a range of areas. These are discussed below with recommendations for further research where appropriate.

## PSG and actigraphy are best used to measure different forms of sleep discrepancy

As the gold-standard for measuring objective sleep, PSG may be considered generally preferable to actigraphy for the measurement of sleep discrepancy. In comparison with PSG, actigraphy generally overestimates sleep and underestimates wake time, and can have trouble distinguishing sleep from quiescent periods of wakefulness [@marino2013]. These trends have been observed to be greater for samples experiencing chronic medical or psychiatric conditions [@conley2019agreement]. Actigraphy is not without its advantages, however, and remains more cost-effective, more useful for obtaining multiple nights of data, and less invasive, compared with PSG. For these reasons, actigraphy is recommended for measuring naturalistic sleep and sleep patterns over time [@morgenthaler2007practice], and may be preferable to PSG where external validity of sleep discrepancy is a concern. Another case where actigraphy is clearly preferable is when aggregate (e.g., mean weekly) objective measures are compared to habitual measures of self-report sleep (see \@ref(dvar) for further discussion of this).

<!-- It has been emphasised that the differences between PSG and actigraphy on these metrics are systematic rather than random () -->


<!-- mentioned...that differences between PSG and actigraphy for variables such as TST, SOL, and WASO, are systematic and, excepting some circumstances, can mostly be attributable to differences in  -->


## Choice of actigraphy algorithm matters {#algo}

Estimation of actigraphic sleep can vary substantially according to scoring algorithm and, considered in relation to PSG, selection of algorithm will account for some error variance within sleep discrepancy. The concordance of actigraphy to PSG by algorithm tends to depend on the sample in question. For example, actiware algorithms with the medium threshold may perform better than Cole-Kripke in healthy young adults [@gao2022actigraphy]. Also, the Sadeh algorithm has demonstrated higher specificity than UCSD and Cole-Kripke [@desouza2003; @quante2018actigraphy; @haghayegh2019accuracy] but may be less appropriate for assessment of sleep in those with severe obstructive sleep apnoea [@kim2013comparison]. Further complicating the picture is the fact that algorithm performance will also differ according to the actigraph device used [@kripke2010wrist]. New algorithms identified in the review included machine learning algorithms by @john2019open and calculations of non-wear time using respiratory information by @barouni2020ambulatory. We noted considerable inconsistency in the reporting of actigraphy methods and algorithms were not reported in many studies. In the absence of a standardised, consensus approach to actigraphy we would like to echo the recommendations of [@ancoli2015sbsm] to report device manufacturer, device model, name and version of software, parameters of data collection including epoch length and sampling rate, and algorithms used.

## Sleep diaries should not be used to define rest intervals in sleep discrepancy research

Sleep diaries were the most commonly identified method of rest interval definition in this review. A sleep diary is a self-report measure of sleep. By using sleep diaries to define actigraphic rest intervals, self-report sleep is being used to partially define an objective sleep measure. In this case, the measured discrepancy between the two forms of sleep measurement will not be an accurate representation of their actual incongruence. The high frequency at which sleep diaries are back-filled or misreported [@clegg2023real] should be well enough to address the doubts of anyone about the significance of this issue. We noted that a single study in the present review, @krahn_assessing_1997, ensured that manual scorers of the rest intervals for their actigraphy data were blinded to the sleep diary. We recommend that for sleep discrepancy research, alternatives such as these are sought for defining rest interval periods.

## Method of calculation of self-report sleep time matters

We identified two principal ways of calculating self-report TST from diaries and sleep questionnaires: querying participants directly about how much sleep they had (e.g., "how many hours did you sleep last night?") and calculating TST from other parameters that were queried directly (e.g., TST = TIB - SOL - WASO - TWAK). The latter method is recommended by @buysse2006 and is the usual practice when using the Consensus Sleep Diary [@Carney2012], a questionnaire that does not contain a direct query for TST in its standard version. @alameddine_2015 compared direct and indirect (i.e., calculated) self-report measures of TST and found that the direct estimates tended to exceed indirect estimates. In this study, sleep discrepancy was overall negative across the sample for those with and without insomnia so it is possible that indirect queries produce self-report TST that is closer to objective estimates (i.e., reduced sleep discrepancy). 

<!--Romola: And what is the implication of all of the above? Tom: I don't know what more to say-->

## Definitions of objective sleep onset latency are multifarious and abritrary {#sol}

Definitions of objective SOL vary considerably in the sleep discrepancy literature. Among PSG studies, the two most common approaches were dependent on standard definitions provided by scoring guidelines: Rechstaffen & Kales (R&K) and the American Academy of Sleep Medicine (AASM). In R&K, sleep onset is defined by three consecutive epochs of stage 1 sleep or one epoch of stage 2 sleep [@rechtschaffen1968]. For AASM, by contrast, an epoch of any stage of sleep indicates sleep onset [@berry2012aasm]. Subjective sleep onset is more likely to coincide with the occurrence of the first sleep spindle, an EEG waveform associated with stage 2 sleep, than with the first incidence of stage 1 sleep [@bonnetmoore1982]. As such, R&K SOL is likely to have greater correspondence to self-report SOL than AASM SOL. This disparity would be expected to increase with greater sleep fragmentation in the early sleep period and substantial differences in AASM and R&K sleep discrepancy should be expected in samples with disrupted initial sleep. Stricter/longer SOL definitions including the Latency to Persistent Sleep [LPS;\ @bianchi_sleep_2012] and complex definitions from @means_2003 and @lehrer_comparing_2022 are expected to have the closest correspondence to self-report SOL, given that a median 22-minutes of uninterrupted sleep is needed for healthy adults to perceive a bout of sleep during the beginning of the night [@hermans_sleep_2020].

@saline_sleep_2016 noted a potential problem for studies that investigate both TST and SOL concurrently. In the estimation of TST, individuals may attempt to judge the length of time between their subjective sleep onset and final wake time--anchoring their TST estimate to their SOL estimate. In measuring TST and SOL discrepancy, SOL discrepancy is thus being tested for twice: once in SOL and again implicitly in TST. Their solution to this problem was to obtain independent measurements by estimating the amount of objective sleep measured during the subjective sleep latency period (sleep during subjective latency; SDSL) and the amount of objective sleep measured following the subjective sleep latency period (latency adjusted total sleep time; LA-TST).

Definitions for objective sleep latency are essentially arbitrary and sleep onset is a continuous process for which it is difficult to identify a clear start-point [@tryon2004]. For example, with PSG scored by AASM criteria, 50% of a 30-second epoch is needed to exhibit sleep for the scoring of a first sleep stage. This means sleep latency is defined as the number of epochs preceding the first uninterrupted \~16 seconds of an EEG depicting activity consistent with sleep. An individual could conceivably achieve this 16-second threshold within two minutes, wake up, and not return for another two hours (SOL = 2 minutes). Equally, an individual could spend a two hour period getting 14-second blocks of sleep before achieving a consolidated bout of sleep (SOL = 120 minutes).

In light of this issues, three options are recommended in the context of sleep discrepancy research. The first is to proceed with defining objective SOL using latency to persistent sleep (LPS)--the first 20 consecutive epochs of sleep. Due to the considerable time it takes to perceive a bout of sleep (see @hermans_sleep_2020) and the rarity and limited magnitude of SOL underestimation (see @saline_sleep_2016) it makes sense to use a longer criterion than a shorter one. LPS also has the advantage of being simpler than some alternatives (see \@ref(fig:SOL)). The second option is to use SDSL for the reasons described in the previous paragraph. It should be noted, however, positive discrepancy (i.e., SOL underestimation) is not measurable with this method. The third option is to avoid SOL as a sleep variable and to model sleep perception parameters during the sleep onset period according to @hermans_sleep_2020. The latter two options have the added advantage of operationalising sleep discrepancy without the use of derived scores--the problems with which are discussed in a later paragraph (\@ref(dvar)) .

## Sleep quality discrepancy is conceptually unclear

Sleep quality discrepancy was measured by a small number of studies in this review, according to varying strategies. Sleep quality discrepancy is a difficult topic for two reasons. First, there is no consensus approach to operationalising sleep quality. A review of methods for measuring sleep quality was conducted by @mendoncca2019review and the scope and number of strategies identified was immense--especially for objective measures. Second, there are no clear self-report analogues for objective measures of sleep quality, or vice-versa. An individual is unable to directly estimate their number of EEG arousals, quantity or proportion of N3 sleep, or other features of sleep macro or microstructure unavailable to consciousness. Equally, it isn't clear how to compare a sleep quality rating judgement (e.g., on a Likert scale) with objective measures [see @krystaledinger2008]. Overall, investigating the relationships of sleep quality discrepancy to other variables is unlikely to be profitable until the conceptual status of self-report and objective sleep quality is clearer.

<!-- Generally, self-report and objective measures of sleep quality do not cohere well @kaplan2017 -->
<!-- As stated by @krystal2008quality "it seems unlikely that such a global rating would be consistently related to a single physiological aspect of sleep".  -->
<!-- Sleep efficiency (SE), the most common objective sleep quality component identified in this review, is unlikely to -->
<!-- Studies by @harvey2008subjective and @libman2016 found that self-report sleep quality in both healthy adults and those experiencing insomnia was typically defined by feelings and mood upon waking, consolidation and continuity of sleep, and daytime functioning.  -->
<!-- Sleep continuity discrepancy could be a good candidate -->
<!-- comparing holistic measures of sleep quality e.g., PSQI not appropriate to compare with nightly objective sleep -->
<!-- Sleep questionnaires such as the PSQI that provide a more global measure of sleep quality -->

## The abundance of arbitrary methodological choices in sleep discrepancy may represent a problem

The term *researcher degrees of freedom* has been used to refer to the range of possible decisions throughout the data collection and analysis process that can be exploited to yield tests that reach statistical significance [@simmons2011]. As evidenced by the methodological diversity highlighted in this review, the amount of researcher degrees of freedom in sleep discrepancy research is considerable, particularly at the data analysis stage, and especially for sleep variable definition and selection. Any combination of the large number of sleep variables in Table \@ref(tab:variables) may be chosen as an alternative analytic decisions during analysis. When the different possible definitions of each of these variables are also enumerated, the number of possible decisions seems endless. Note, this issue extends beyond the case of a researcher deliberately exploring analytical alternatives following a null result. In a problem referred to as the garden of forking paths [@gelman2013],
any methodological decision made in response to an observed feature of the data increases the likelihood that findings will be misleading. An example of this would be selecting SE over TST for a subsequent analysis after observing that SE discrepancy best discriminated individuals with and without insomnia. Even though the eventual result is at this point unknown, the decision of sleep variable is contingent on the data, and ultimately, p-values will not reflect what would have happened had TST been chosen instead. As a solution to this, for studies aimed at investigating the relationship of sleep discrepancy with other constructs, we recommend the preregistration of hypotheses and plans for data collection and analysis [@nosek2018].

<!-- Often, theoretical justification is not provided for the selection or definition of sleep variables to define operationalise sleep discrepancy. This is understandable, given the sheer number of ways to measures sleep and the lack of available evidence to clarify their conceptual differences (is this too much of an assertion?). To return to the previous example of selecting TST versus SE, and putting the issue of false positives aside, if both sleep variables were assessed what would it mean to obtain a significant result from SE but not TST?  -->

<!-- Is to think less about sleep discrepancy as a monolithic entity and more in terms of the conceptual bases of its components. -->
<!-- Discrepancy in a particular construct drastically increases conceptual and methodological complexity -->

## Derived variables including difference and ratio scores should be avoided in most cases {#dvar}

Derived variables was overwhelmingly the most common way of operationalising sleep discrepancy to investigate its relationship with other variables. Derived variables including difference scores and ratio scores are associated with a range of conceptual and methodological problems [@Cronbach1970; @edwards2002; @Kronmal1993] that are severe enough to warrant discontinuing their use in sleep discrepancy research. A detailed treatment of these problems is beyond the scope of the discussion, for more information see (methods paper reference). Stated briefly, in a relationship with another variable, the effect of each component of a derived score (i.e., self-report and objective sleep) is confounded such that it is not possible to determine whether self-report sleep, objective sleep, or some combination of the two are driving the relationship. Moreover, derived scores impose inappropriate constraints on relationships between other variables that are often not verbalised in, or else completely contradictory to stated hypotheses. We would encourage researchers to employ alternative strategies identified in this review including classification performance metrics, moderation/interaction effects, and the modelling of sleep discrepancy parameters.

## Averaging sleep variables across multiple nights is problematic in most cases

In the studies identified in this review, the most common way of handling repeated measurements of sleep variables was by averaging across multiple instances of recording. This technique is problematic when applied to concurrent nightly or episodic measurements of self-report and objective sleep as it relies on the assumption that patterns of sleep over/ underestimation are consistent across nights. Extreme positive and negative sleep discrepancy occurring alternately on successive nights could result in averages denoting negligible discrepancy. This may be a realistic concern for research in sleep discrepancy and insomnia, for example. Although most individuals with insomnia tend to underestimate sleep, high inter-night variability is observed and some individuals will overestimate sleep [@trajanovic2007, @telindert_2020]. An exception to this problem exists in the case of comparing aggregated objective sleep against a habitual measure of self-report sleep, such as the PSQI. Here, using means or medians to determine habitual measures of objective sleep is necessary to define sleep discrepancy at the habitual, rather than the nightly level. In other cases, linear mixed models, generalised estimating equations, and structural equation models were methods identified in this review that do not inherit the same problems with averaging across repeated measures.

## Correlation is not a meaure of concordance

Despite being the most common approach to comparing self-report and objective sleep measures, Pearson or Spearman correlations are broadly inappropriate for the characterisation of agreement or discrepancy. Correlation is strictly a measure of association between two variables and is insensitive to systematic error between measures [@jinyuan2016]. For example, the same correlation coefficient may equally describe a sample where self-report and objective estimates of sleep tend to be equal as one where (i), objective estimates tend to exceed self-report estimates by a given constant (e.g., two hours) or (ii), the value of objective sleep varies proportional to the level of self-report sleep. Measures of agreement including Bland-Altman analyses, intra-class correlation, and Lin's concordance coefficient are preferable for the measurement of discrepancy in equivalent parameters.

## Sleep discrepancy varies in its conceptual distance to sleep misperception {#misp}

Sleep discrepancy is a term often used interchangeably with sleep misperception. It has been noted by a number of authors [@Moul2004; @tryon2004] that sleep is a complex process for which there no one perfectly valid measure and accordingly *sleep discrepancy* is a preferable term to *sleep misperception* which in this context may be a misnomer. The status of visually-scored EEG as a clear objective standard of sleep continues to be challenged by the presence of local sleep [@krueger2019local], subtle EEG changes (e.g., the cyclic alternating pattern [@Parrino2012]), and dissociation identified between the EEG and other sleep-related physiological processes, under some conditions [@krueger2013sleep]. Whilst it may not be possible to directly measure sleep misperception for these reasons, sleep discrepancy can be closer or further to sleep misperception conceptually depending on its operational definition. Closest are studies measuring sleep/wake agreement or classification using EEG under laboratory conditions. In a case where a participant who, being asleep for 5 minutes, is woken by a technician and reports complete wakefulness for the preceding period, only the fallibility of objective recording can account for a conceptual distinction between sleep discrepancy and true sleep-state misperception.

This fundamental sleep discrepancy represented by sleep-wake agreement can be contrasted with sleep discrepancy represented by sleep time variables (e.g., TST, SOL). Moving from sleep-wake agreement to sleep time variables introduces additional factors that may account for the incongruence between self-report and objective sleep and hence provides a broader definition of sleep discrepancy. On the objective side, PSG potentially introduces artefact from transient (e.g., \<15 second) awakenings (ref) and the somewhat arbitrary nature of SOL definitions (see section \@ref(sol). Actigraphy introduces the potential for immobile wake to be scored as sleep [@desouza2003,@paquet2007] and variance contributed by differences in scoring algorithms (see section \@ref(algo)). On the self-report side, sleep diaries and questionnaires introduce memory or reporting biases [@clegg2023real] as potential factors contributing to sleep discrepancy. See Harvey & Tang 2012 for a discussion of these factors in the context of insomnia.

In the present review, we reported a key distinction between *habitual* and *episodic* measures of self-report sleep. Moving from episodic to habitual measures broadens the concept of yet sleep discrepancy further. A more global sleep discrepancy may be represented by comparisons of habitual self-report sleep with aggregated objective sleep (e.g., mean sleep variables values across 14 nights of actigraphy), the underlying processes for which are likely different to those of individual nights.

Where habitual self-report sleep is compared to objective estimates spanning one to a few nights, intra-individual variation in sleep patterns is introduced to sleep discrepancy. In other words, some component of the difference between objective and self-report sleep can be accounted for by the difference between habitual sleep and the circumstances of testing--which may be substantial. If the objective measure is PSG, effects of the laboratory/testing environment [i.e., the first night effect, see: @Agnew1966, @newell2012one] are additionally introduced.

## The scope of sleep discrepancy research is likely to have been underestimated

The scope of the literature on sleep discrepancy has been considerably underestimated to date. We intended to identify a broad range of studies in this review that may have captured the concept of sleep discrepancy without necessarily referring to this or related terms. A search across full texts of all studies included in this review returned `r (grepl("discrepancy", screen$abstract, ignore.case = TRUE) & grepl("sleep", screen$abstract, ignore.case = TRUE)) %>% sum()` records making explicit mention of "sleep" and "discrepancy", leaving `r nrow(screen) - (grepl("discrepancy", screen$abstract, ignore.case = TRUE) & grepl("sleep", screen$abstract, ignore.case = TRUE)) %>% sum()` that would have otherwise been unidentifiable through simple keyword searching of this concept. A prior review of paradoxical insomnia and subjective-objective sleep discrepancy [@Rezaie2018] identified a total of 40 records. Although conducted four years prior, this review used broader inclusion criteria extending to paradoxical insomnia, the parameters for which do not typically involve direct comparisons of self-report and objective sleep. A corollary to the presence of this underestimation of breadth is that existing sleep discrepancy research across domains may be excessively siloed into respective research areas. Looking at the clinical populations encompassed in this review, there appear to be small but distinguishable sleep discrepancy research programmes in post-traumatic stress disorder, bipolar disorder, pregnancy, traumatic brain injury, and fibromyalgia, to name just a few. Whilst sleep discrepancy is best understood in the context of insomnia, it is possible similar processes underlie the presence of sleep discrepancy in these groups. For example, the role of sleep disturbance as a transdiagnostic factor across psychiatric disorders has been emphasised [@harvey2011sleep] and a mechanistic role for sleep misperception has been suggested for disorders outside of insomnia [@richardson2016].

## Strengths and limitations {#item20}

This study represents the largest systematic approach to investigating methodology in the area of sleep discrepancy research. We reported a broad range of methodological features across a large number of studies and provided meaningful syntheses of research methods in a field marked by considerable methodological diversity. Two major changes were made to our own methods during the screening process and following registration of the scoping review protocol that may be viewed as limitations. These changes were both made in response to the unanticipated number of records returned following title and abstract screening and in view of limited resources available for charting and synthesis. First, grey literature was removed from inclusion criteria. Although the issues and recommendations discussed in this paper were limited to published research, our findings remain broadly applicable and no syntheses of empirical findings have been made that could be influenced by publication bias. Second, reference lists were not screened for additional studies and the extent to which this review may be considered an exhaustive representation of the literature may be reduced as a result. 

## Summary {#item21}

Approaches to measuring and operationalising sleep discrepancy have varied considerably in the literature, often with substantial effects on what sleep discrepancy means as a concept and sometimes associated with problems that may not be immediately clear. Measuring discrepancy or congruence is often a complex undertaking and we hope that this scoping review will prove helpful and informative to those interested in designing or interpreting sleep discrepancy studies.

<!-- it may be more effective or simpler to not measure sleep discrepancy at all -->

<!-- Provide a general interpretation of the results with respect to the review questions and objectives, as well as potential implications and/or next steps. -->

# Acknowledgements

We would like to thank the librarians at the University of Western Australia library for their assistance with the development of the search strategy.

# Financial disclosure statement

None.

# Funding {#item22}

This work was part of a PhD project funded by the Australian Government Research Training Program.

# Declaratation of competing interest

The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.

# Appendices

## Search strategies

Search strategies for databases searched using the Ovid system are available in Table \@ref(tab:ovid). Search strategies for other databases are listed in Table \@ref(tab:databases).

``` {r ovid, echo = FALSE, warning = FALSE, message = FALSE}
col1 <- c(seq(1:7), seq(1:7), seq(1:7))
col2 <- c('sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actimetry/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6',
          'sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actigraphy/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6',
          'sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actigraphy/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6'
)
col3 <- c(488, 193243, 1676, 9362, 193302, 1234, 1569, 175, 57592, 59, 2112, 57592, 346, 471, 260, 139088, 561, 5280, 139088, 692, 875)
df <- data.frame("step" = col1, "terms" = col2, "records" = col3)
colnames(df) <- c("Step", "Terms and operators", "Records")

kable(df,
      format = "html",
      caption = "Search strategy for Ovid databases"
) %>%
  kable_styling(font_size = 11, full_width = F) %>%
  pack_rows("Embase", 1,7) %>%
  pack_rows("PsycINFO", 8,14) %>%
  pack_rows("Medline", 15,21)

```

``` {r databases, echo = FALSE, warning = FALSE, message = FALSE}

col1 <- c(
'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*)) OR (("Polysomnography/methods"[MAJR] OR "Actigraphy/methods"[MAJR]) AND "Self Report"[MeSH])
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'TITLE-ABS-KEY ( ( "sleep discrepancy"  OR  "paradoxical insomnia"  OR  "subjective insomnia" )  OR  ( sleep  AND  misperception )  OR  ( ( "self report*"  OR  diary  OR  subjective* )  AND  ( objective*  OR  actigraph*  OR  polysomnograph*  OR  polygraph* ) )  AND  ( sleep*  AND  ( "over estimat*"  OR  "over report*"  OR  "under estimat*"  OR  "under report*"  OR  overestimat*  OR  overreport*  OR  underestimat*  OR  underreport*  OR  discrepan*  OR  concordan*  OR  agreement  OR  disagreement  OR  discordan*  OR  congruen*  OR  incongruen* ) ) ) ',

'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'noft(("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
((("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* 
OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))))'
)

col2 <- c(761, 310, 826, 1288, 90)
df <- data.frame("terms" = col1, "records" = col2)
colnames(df) <- c("Terms and operators", "Records")

kable(df,
      format = "html",
      caption = "Search strategy for other databases"
      ) %>%
  kable_styling(font_size = 11, full_width = F) %>%
  pack_rows("Pubmed", 1,1) %>%
  pack_rows("CINAHL Plus", 2,2) %>%
  pack_rows("Scopus", 3,3) %>%
  pack_rows("Web of Science", 4,4) %>%
  pack_rows("Proquest Theses and Dissertations Global", 5,5)

```

## List of deviations from protocol

The following are a list of deviations from the scoping review protocol registered on the Open Science Framework (doi: 10.17605/OSF.IO/BCJNQ).

1. The term actimetry in Medline and PSYCinfo searches was changed to actigraphy
2. The scoping review protocol listed an incorrect number of duplicates records following searches
2. All records that were not peer reviewed journal articles were excluded at the full-text screening stage in the final review
3. Other items were added to the exclusion criteria at the full-text screening stage including:
 + study measured informant-report rather than strictly self-report sleep
 + study did not include statistical comparison of self-report and objective sleep (e.g., numerical comparisons only, single-case design)
4. Reference lists were not searched for additional citations as planned in the protocol

## PRISMA-ScR checklist

``` {r checklist, echo = FALSE, warning = FALSE, message = FALSE}

col1 <- c(
  "Title", "Structured summary", "Rationale", "Objectives", "Protocol and registrations", "Eligibility criteria", "Information sources", "Search", "Selection of sources of evidence", "Data charting process", "Data items", "Critical appraisal of individual sources of evidence", "Synthesis of results", "Selection of sources of evidence", "Characteristics of sources of evidence", "Critical appraisal within sources of evidence", "Results of individual sources of evidence", "Synthesis of results", "Summary of evidence", "Limitations", "Conclusions", "Funding"
)

col2 <- seq(1:22)

col3 <- c(
  "Identify the report as a scoping review.",
  "Provide a structure summary that includes (as applicable): background, objectives, eligibility criteria, sources of evidence, charting methods, results, and conclusions that relate to the review questions and objectives.",
  "Describe the rationale for the review in the context of what is already known. Explain why the review questions/ objectives lend themselves to a scoping review approach",
  "Provide an explicit statement of the questions and objectives being addressed with reference to their key elements (e.g., population or participants, concepts, and context) or other relevant key elements used to conceptualise the review questions and/or objectives.",
  "Indicate whether a review protocol exists; state if and where it can be accessed (e.g., a Web address); and if available, provide registration information, including the registration number.",
  "Specify characteristics of the sources of evidence used as eligibility criteria (e.g., years considered, language, and publication status), and provide a rationale.",
  "Describe all information sources in the search (e.g., databases with dates of coverage and contact with authors to identify additional sources), as well as the date the most recent search was executed.",
  "Present the full electronic search strategy for at least 1 database, including any limits used, such that it could be repeated.",
"State the process for selecting sources of evidence (i.e., screening and eligibility) included in the scoping review.",
"Describe the methods of charting data from the included sources of evidence (e.g., calibrated forms or forms that have been tested by the team before their use, and whether data charting was done independently or in duplicate) and any processes for obtaining and confirming data from investigators.",
"List and define all variables for which data were sought and any assumptions and simplifications made",
"If done, provide a rationale for conducting a critical appraisal of included sources of evidence; describe the methods used and how this information was used in any data synthesis (if appropriate).",
"Describe the methods of handling and summarizing the data that were charted",
"Give numbers of sources of evidence screen, assessed for eligibility, and included in the review, with reasons for exclusions at each stage, ideally using a flow diagram.",
"For each source of evidence, present characteristics for which data were charted and provide the citations.",
"If done, present data on critical appraisal of included sources of evidence (see item 12).",
"For each included source of evidence, present the relevant data that were charted that relate to the review questions and objectives.",
"Summarize and/or present the charting results as they relate to the review questions and objectives.",
"Summarize the main results (including an overview of concepts, themes, and types of evidence available), link to the review questions and objectives, and consider the relevance to key groups",
"Discuss the limitations of the scoping review process.",
"Provide a general interpretation of the results with respect to the review questions and objectives, as well as potential implications and/or next steps.",
"Describe sources of funding for the included sources of evidence, as well as sources of funding for the scoping review. Describe the role of the funders of the scoping review."
)

# Double backslash so rmarkdown doesn't read it as an escape

col4 <- c("\\@ref(abstract)", #item1
          "\\@ref(abstract)", #item2
          "\\@ref(introduction)", #item3
          "\\@ref(introduction)", #item4
          "\\@ref(protocol)", #item5
          "\\@ref(item6)",
          "\\@ref(item7)",
          "\\@ref(tab:egsearch)", #item8
          "\\@ref(item9)",
          "\\@ref(item10)",
          "\\@ref(item11)",
          "Formal quality assessment was not conducted", #item12
          "\\@ref(item13)",
          "\\@ref(item14)",
          "\\@ref(item15)",
          "Formal quality assessment was not conducted", #item16
          "\\@ref(resultsandsynthesis)", #item17
          "\\@ref(resultsandsynthesis)", #item18
          "\\@ref(item19)",
          "\\@ref(item20)",
          "\\@ref(item21)",
          "\\@ref(item22)"
          )

df <- data.frame("section" = col1, "item_no" = col2, "item" = col3, "page" = col4)
colnames(df) <- c("Section", "Item", "PRISMA-ScR Checklist Item", "Location reported")

kable(df,
      format = "html",
      caption = "Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) Checklist."
) %>%
  kable_styling(font_size = 11, full_width = F) %>%
  pack_rows("Title", 1,1) %>%
  pack_rows("Abstract", 2,2) %>%
  pack_rows("Introduction", 3,4) %>%
  pack_rows("Methods", 5, 13) %>%
  pack_rows("Results", 14, 18) %>%
  pack_rows("Discussion", 19, 21) %>%
  pack_rows("Funding", 22, 22)


```

## Test
``` {r test, echo = FALSE, warning = FALSE, message = FALSE}
df <- subset(screen, select = c(bibkey,
                                sample_characteristics,
                                sample_size,
                                aim_agreement,
                                aim_construct,
                                aim_validation))

# add an '@' sign in front of each key 
df$bibkey <- paste0("@",df$bibkey)

df$study_no <- seq(1:nrow(df))

kable(df, format = "html") %>%
kable_styling(font_size = 11, full_width = F)



```
# References
