---
title: 'A scoping review of sleep discrepancy methodology: do we know what we are measuring?'
author:
- name: Tom F. Walton
  affiliation: School of Psychological Science, The University of Western Australia
- name: Melissa J. Ree
  affiliation: School of Psychological Science, The University of Western Australia
- name: Simone N. Fueggle
  affiliation: CALHN Neuropsychology, Royal Adelaide Hospital
- name: Romola S. Bucks
  affiliation: School of Psychological Science, The University of Western Australia
date: "2024-05-3"
output:
  rticles::arxiv_article:
    latex_engine: xelatex
    keep_tex: true
bibliography:
- references_body.bib
- references_review.bib
- references_acti.bib
- references_packages.bib
csl: "apa.csl"
always_allow_html: true
---

```{r initial code, echo = FALSE, warning = FALSE, message = FALSE}

################################ Initial code ##################################

# packages

library("tidyverse")
library("bookdown")
library("knitr")
library("kableExtra")
library("english")
library("DiagrammeR")   # for PRISMA flowchart
library("networkD3")
library("webshot")

# Read data set into data frame
full_screen <- read.csv("../data/review_data.csv")

# Trim excluded studies from the data frame
screen <- filter(full_screen, fulltext_include=="Yes" | fulltext_include=="Second study")

#========  Functions to make inline code easier to read (enclose arguments in "")  =========

# catg counts string values equal to second arg in column name (first argument)

catg <- function(x, y, brackets = TRUE) {
  i <- which(colnames(screen) == x)
  
  if (brackets == FALSE) {
    length(which(screen[ ,i] == y))
    }
  else {
  paste0 ("(n = ",
         length(which(screen[ ,i] == y)),
         ")") %>%
         I() # print result "as is"
  }
}

# onehot finds the sum of a column defined by the argument

onehot <- function(x, brackets = TRUE) {
  i <- which(colnames(screen) == x)
  
  if (brackets == FALSE) {
    sum(screen[ ,i], na.rm=TRUE)
  }
  else {
  paste0  ("(n = ",
          sum(screen[ ,i], na.rm=TRUE),
          ")") %>%
          I() # print result "as is"
  }
}

#=================   End of functions   ===================

# Assign some screening variables
duplicates <- 3903 %>% format(nsmall=0, big.mark=",")
total_records <- 6190 %>% format(nsmall=0, big.mark=",")
```

# Abstract {#abstract}

## Study Objectives 

To examine how past studies have conceptualised sleep discrepancy and identify and evaluate the methods used.

## Method

We searched MEDLINE, Embase, PsycINFO, CINAHL Plus, PubMed, Scopus, and Web of Science in April 2022 for studies comparing self-report and objective measures of sleep. Methodological information was extracted from relevant studies and included measures of self-report and objective sleep, sleep variables (e.g., total sleep time), derived discrepancy indices (e.g., difference scores), handling of repeated measurements, and methods of measure comparison (e.g., Bland-Altman analyses).

## Results

`r length(which(full_screen$fulltext_include == "Yes")) %>% english() %>% str_to_sentence` relevant records were identified. Studies varied according to objective sleep measure; actigraphy algorithm, software, and rest interval; polysomnography setting and scoring criteria; sleep variables; self-report sleep measure; number of nights of objective recording; time frame of self-report measure; self-report sleep variable definition; sleep discrepancy derived index; presence and handling of repeated measurements; and statistical method for measure comparison.

## Conclusions

Sleep discrepancy was mostly conceived as discordance in sleep states or sleep time variables, and various forms of this discordance differed in their conceptual distance to sleep misperception. Furthermore, studies varied considerably in methodology with critical conceptual and practical implications that have received little attention to date. Substantive methodological issues were also identified relating to the use of derived indices for operationalising sleep discrepancy, defining objective sleep onset latency, calculating actigraphy rest intervals, measuring correlation and concordance, averaging sleep variables across nights, and defining sleep quality discrepancy.

## Key words

Sleep discrepancy; sleep misperception; scoping review

## Statement of Significance

Sleep discrepancy, the discordance between self-report and objective measures of sleep, is an important feature for theory in insomnia and a key issue in sleep measurement. Despite the considerable research in this area, the status of sleep discrepancy as a concept is unclear and varied methodologies are employed with unknown theoretical or conceptual implications. This scoping review integrates a comprehensive range of methodological details from sleep discrepancy studies, clarifying the concept of sleep discrepancy and critically evaluating approaches to its measurement. The broad view of the literature afforded by the systematic search allows us to identify and discuss conceptual and methodological issues that have received little attention and are critical for the advancement of research in sleep discrepancy. 

# Introduction {#introduction}

Sleep is measured in two principal ways: objectively through polysomnography or actigraphy, and by self-report through questionnaires or sleep diaries. The discordance that can exist between these two forms of measurement is known as subjective-objective sleep discrepancy, or more simply, sleep discrepancy. Sleep discrepancy is a common feature of insomnia disorder, where it is also referred to as sleep misperception or paradoxical insomnia. Individuals with insomnia tend to underestimate total sleep time (TST), and overestimate sleep onset latency (SOL) and wake after sleep onset (WASO) relative to objective measures [@Baglioni2014; @edinger_1995; @means_2003] and are more likely to report prior wakefulness after being woken in laboratory studies [@mendelson_1986; @mercer_2002].

There are diverse ways to conceptualise, and measure sleep discrepancy. It may be considered as a spectrum [@trajanovic_2007], ranging from positive (self-report exceeds objective) to negative (objective exceeds self-report), or as a measure of absolute sleep agreement [@baillet_2016]. Any number of sleep variables such as TST, SOL, or WASO can used to operationalise sleep discrepancy, each differing conceptually and carrying varying theoretical implications. Sleep discrepancy may even be considered beyond these sleep time-based metrics and represent discordance in self-report and objective sleep patterns [@allawati_2021], or sleep quality. Sleep discrepancy can be characterised in a sample by directly comparing self-report and objective sleep with a range of statistical techniques. Other studies may derive variables to define sleep discrepancy quantitatively to measure its relationship with other variables, for example using a difference score of self-report TST -- objective TST.

To date, there have been few systematic attempts to synthesise or evaluate the varied approaches to investigating sleep discrepancy. Three reviews have been conducted in this area. Castelnovo et al [@Castelnovo2019] conducted a systematic review of quantitative definitions of paradoxical insomnia, an insomnia subvariant defined, in part, by the presence of sleep discrepancy. This excluded studies where sleep discrepancy was not used to form diagnostic criteria. Two subsequent reviews were conducted by Rezaie et al [@Rezaie2018] and Stephan et al [@stephan2023] focussing on paradoxical insomnia and the correlates of sleep misperception, respectively. Whilst informative discussions of research findings, these studies excluded a focus on concepts or methodology.

Consequently, sleep discrepancy remains an ambiguous construct, with conceptual and methodological sources of variation that are yet to be formally delineated. This threatens the development of theory in research areas such as insomnia as it can be unclear whether sleep discrepancy studies are measuring or operationalising the same or different phenomena. The replicability of findings can also be affected where the proliferation of varying analysis strategies introduces uncertainty into the data analysis process [@hoffmann2021]. Research is needed to integrate and evaluate the varied approaches to sleep discrepancy, clarify its conceptual boundaries, and facilitate comparisons across studies.

A scoping review is a method of research synthesis that aims to map existing literature in a field of interest and identify types of evidence available in a given topic [@Arksey2005]. We used a scoping review strategy to examine how sleep discrepancy has been conceptualised in the literature and identify and evaluate the methods used to investigate it. A preliminary search of MEDLINE (Ovid), the Cochrane Library, Embase (Ovid), and PsycINFO (Ovid) was conducted to identify existing or in-progress systematic or scoping reviews on the topic. Except for the three reviews mentioned above, no records were identified.

# Methods

## Protocol and registration {#protocol}

The review was conducted according to guidelines provided by the JBI scoping review methodology group [@Peters2020] and reported according to the Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) Checklist [@tricco2018]. A review protocol was registered with the Open Science Framework on April 4, 2022 (doi: 10.17605/OSF.IO/BCJNQ), prior to conducting searches. Deviations from the protocol are outlined in the appendices (\@ref(deviations)).

## Eligibility criteria {#item6}

Participants of all age groups and clinical populations were included in the review. To adequately map the boundaries of sleep discrepancy as a concept, we included any study that compared an objective measure of sleep (e.g., polysomnography, actigraphy) with an equivalent self-report measure of sleep (e.g., sleep diaries, questionnaires), through statistical analysis or composite index scores. For measures of self-report and objective sleep, we included traditional indices of sleep time such as TST, SOL, and WASO, in addition to measures of sleep quality, sleep patterns, or any other sleep-related experience or behaviour.

## Exclusion criteria

Studies were excluded that (i) made no direct comparisons between equivalent self-report and objective sleep measures, (ii) included informant, rather than self-report measures, (iii) were case reports or review articles, (iv) were limited to self-report or objective measures not related to sleep, (v) contained no empirical data, (vi) omitted either a self-report or equivalent objective measure of sleep, or (vii) were a grey literature source including theses, dissertations, and conference abstracts. No records were excluded on the basis of geographic location, cultural factors, or any other contextual feature.

## Search strategy {#item7}

The search strategy aimed to identify articles published in peer-reviewed journals and, initially, grey literature including theses, dissertations, and conference abstracts. Due to the large number of records returned by initial searches, grey literature was excluded at the full text extraction stage. The following databases were searched: MEDLINE (Ovid), Embase (Ovid), PsycINFO (Ovid), CINAHL Plus, PubMed, Scopus, Web of Science, ProQuest Theses and Dissertations, and OSF Preprints. The search strategy included keywords, index terms, and search operators adapted for each database. Searches across all databases were conducted on the 24^th^ April 2022. The full search strategy for Embase (Ovid) is provided as an example in Table \@ref(tab:egsearch) below. See Appendix A for full search strategies for other databases.

```{r egsearch, echo = FALSE, warning = FALSE, message = FALSE}
col1 <- seq(1:7)
col2 <- c('sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actimetry/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6'
          )
col3 <- c(488, 193243, 1676, 9362, 193302, 1234, 1569)
df <- data.frame("Step" = col1, "Terms and operators" = col2, "Records" = col3)

kable(df,
      format = "latex",
      booktabs = TRUE,
      col.names = c("Step","Terms and Operators", "Records"),
      caption = "Search strategy for Embase (Ovid)"
      ) %>%
  kable_styling(font_size = 10, full_width = FALSE) %>%
  column_spec(1, width = "1cm") %>%
  column_spec(2, width = "13cm")
```

## Sources of evidence selection {#item9}

Records identified from searches were exported to EndNote 20 [@EndNote20] for collation and then uploaded to Rayyan [@Ouzzani2016] for deduplication and title and abstract screening. Two independent reviewers (TW and SF) screened titles and abstracts to identify studies for full-text retrieval using the inclusion criteria. Percentage of agreement between reviewers was 87.6% and conflicts were resolved via discussion. The full-texts of articles passing title and abstract screening were screened by TW with reasons for exclusion reported. Due to the unanticipated size of the literature, articles from sources other than peer-reviewed journals were added to exclusion criteria post-hoc.

## Charting the data {#item10}

Data extraction was performed by TW, independently. Methodological features of included articles were selected on their potential influence on the measurement or operational definition of sleep discrepancy and included the following: objective sleep measure type/hardware, actigraphy algorithm, software, and rest interval, polysomnography setting and scoring criteria, self-report sleep measure, sleep variables (e.g., TST, WASO etc...) and definitions thereof, methods of handling repeated measurements, methods of comparing self-report and objective sleep within groups, and methods for operationalising sleep discrepancy to investigate its relationship with other variables.

## Data items {#item11}

Extracted data items numbered in the hundreds and are described comprehensively in the codebook available at: https://github.com/tfwalton/sleep-discrepancy-review/raw/main/codebook.xlsx.

## Synthesis of results {#item13}

This manuscript, including all tables and figures summarising data were generated using computationally reproducible methods [@piccolo2016; @lindsay2023] in R version 4.3.2 [@r], with R Studio [@rstudio] and R Markdown [@rmarkdown]. Packages used in the code for this manuscript include tidyverse [@tidyverse], bookdown [@bookdown], knitr [@knitr], kableExtra [@kableextra], english [@english], and DiagrammeR [@diagrammer]. All code and data are available through the Github repository: https://github.com/tfwalton/sleep-discrepancy-review.

# Results {#item14}

The initial search of databases returned `r total_records %>% format(nsmall=0, big.mark=",")` from which `r duplicates %>% format(nsmall=0, big.mark=",")` duplicate articles were removed. Details of the review process from article identification, screening, and selection are available in the PRISMA flowchart depicted in Figure \@ref(fig:PRISMA) below.

```{r PRISMA, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "PRISMA flowchart", fig.height = 12}
###############################################################################
############################# PRISMA flowchart ################################
#-----------------------------------------------------------------------------#

# Records identified
Embase <- 1569 %>% format(nsmall=0, big.mark=",")
PsycInfo <- 471 %>% format(nsmall=0, big.mark=",")
MEDLINE <- 875 %>% format(nsmall=0, big.mark=",")
Pubmed <- 761 %>% format(nsmall=0, big.mark=",")
CINAHL <- 310 %>% format(nsmall=0, big.mark=",")
SCOPUS <- 826 %>% format(nsmall=0, big.mark=",")
WOS <- 1288 %>% format(nsmall=0, big.mark=",")
Proquest <- 90 %>% format(nsmall=0, big.mark=",")

# Total from all databases 6190

duplicates <- 3894 %>% format(big.mark=",")
screened <- 2296 %>% format(big.mark=",")
excluded <- 1641 %>% format(big.mark=",")
sought <- 655 %>% format(nsmall=0, big.mark=",")
assessed <- 655 %>% format(nsmall=0, big.mark=",")

# No direct comparisons between equivalent parameters
excluded1 <- length(which(full_screen$exclusion_code == 1))        
# Informant report only
excluded2 <- length(which(full_screen$exclusion_code == 2))        
# Duplicate
excluded3 <- length(which(full_screen$exclusion_code == 3))         
# Case report
excluded4 <- length(which(full_screen$exclusion_code == 4))         
# Self-report or objective measures not related to sleep
excluded5 <- length(which(full_screen$exclusion_code == 5))         
# Review article
excluded6 <- length(which(full_screen$exclusion_code == 6))         
# Not empirical study
excluded7 <- length(which(full_screen$exclusion_code == 7))        
# Article in language other than English
excluded8 <- length(which(full_screen$exclusion_code == 8))        
 # Either self-report or objective measure not included
excluded9 <- length(which(full_screen$exclusion_code == 9)) 
# Grey literature source
excluded10 <- length(which(full_screen$exclusion_code == 10))     


ftexcluded <- excluded1 + excluded2 + excluded3 + excluded4 + excluded5 + excluded6 +
  excluded7 + excluded8 + excluded9 + excluded10

final_total <- length(which(full_screen$fulltext_include == "Yes"))

#------------------------------------------------------------------------------#    
###################   Prepare vectors for GraphViz   ###########################
#------------------------------------------------------------------------------#      

titles <- c("Records identified from",
            "Duplicate records removed",
            "Records screened",
            "Records excluded",
            "Reports sought for retrieval",
            "Reports assessed for eligibility",
            "Reports excluded",
            "Total studies included in review"
)

list_identified <- c(paste0("Embase ","(n = ", Embase, ")"),
                     paste0("PsycINFO ","(n = ", PsycInfo, ")"),
                     paste0("MEDLINE ","(n = ", MEDLINE, ")"),
                     paste0("PubMed ","(n = ", Pubmed, ")"),
                     paste0("CINAHL Plus","(n = ", CINAHL, ")"),
                     paste0("SCOPUS ","(n = ", SCOPUS, ")"),
                     paste0("Web of Science ","(n = ", WOS, ")"),
                     paste0("Proquest Theses and Dissertations Global ","(n = ", Proquest, ")")
)

list_duplicates <- c(paste0("(n = ", duplicates, ")"))
list_screened <- c(paste0("(n = ", screened, ")"))
list_excluded <- c(paste0("(n = ", excluded, ")"))
list_sought <- c(paste0("(n = ", sought, ")"))
list_assessed <- c(paste0("(n = ", assessed, ")"))

list_ftexcluded <- c(paste0("(n = ", ftexcluded, ")"),
                     paste0("No direct comparisons between equivalent parameters ","(n = ", excluded1, ")"),
                     paste0("Informant report only ","(n = ", excluded2, ")"),
                     paste0("Duplicate (missed at deplication stage; n = ", excluded3, ")"),
                     paste0("Case report ","(n = ", excluded4, ")"),
                     paste0("Self-report or objective measures not related to sleep ","(n = ", excluded5, ")"),
                     paste0("Review article ","(n = ", excluded6, ")"),
                     paste0("Not empirical study ","(n = ", excluded7, ")"),
                     paste0("Article in language other than English ","(n = ", excluded8, ")"),
                     paste0("Either self-report or objective measure not included ","(n = ", excluded9, ")"),
                     paste0("Grey literature source ","(n = ", excluded10, ")")
)

list_total <- c(paste0("(n = ", final_total, ")"))

#------------------------------------------------------------------------------#    
######################     Generate flow chart     #############################
#------------------------------------------------------------------------------# 

graph <- "
digraph { 


graph[layout = dot, rankdir = TB]
node[shape = box, fontsize = 12, width = 4];

      {rank=same identified duplicates}
      {rank=same screened excluded}
      {rank=same assessed ftexcluded}

        identified [label = '@@1-1\\l     @@2-1\\l     @@2-2\\l     @@2-3\\l     @@2-4\\l     @@2-5\\l     @@2-6\\l     @@2-7\\l     @@2-8\\l']
        duplicates [label = '@@1-2 @@3-1']
        screened [label = '@@1-3 @@4-1']
        excluded [label = '@@1-4 @@5-1']
        sought [label = '@@1-5 @@6-1']
        assessed [label = '@@1-6 @@7-1']
        ftexcluded [label = '@@1-7 @@8-1\\l      @@8-2\\l     @@8-3\\l     @@8-4\\l     @@8-5\\l     @@8-6\\l     @@8-7\\l     @@8-8\\l     @@8-9\\l     @@8-10\\l     @@8-11\\l']
        total [label = '@@1-8 @@9-1']

identified -> duplicates
identified -> screened
screened -> excluded
screened -> sought
sought -> assessed
assessed -> ftexcluded
assessed -> total


}
    [1]: titles
    [2]: list_identified
    [3]: list_duplicates
    [4]: list_screened
    [5]: list_excluded
    [6]: list_sought
    [7]: list_assessed
    [8]: list_ftexcluded
    [9]: list_total
"
grViz(graph, height = "100%")
```

## Article characteristics
A total of `r nrow(screen)` studies were identified from `r catg("fulltext_include", "Yes", brackets = FALSE) ` records, with `r catg("fulltext_include", "Second study", brackets = FALSE) %>% english()` records reporting two studies or experiments within a single text. Records spanned `r unique(c(screen$country, screen$country2)) %>% length()` countries, with the majority originating from the USA (n = `r length(which(screen$country == "USA" | screen$country2 == "USA"))`).

```{r sample sizes, echo = FALSE, warning = FALSE, message = FALSE}
sample_size <- as.numeric(screen$sample_size)
```

Sample sizes for studies ranged from `r min(sample_size, na.rm=TRUE)` to `r max(sample_size, na.rm=TRUE) %>% format(nsmall=0, big.mark=",")` (median = `r median(sample_size, na.rm=TRUE)`, IQR = `r IQR(sample_size, na.rm=TRUE)`). Most studies included both sexes in their samples (n = `r length(which(screen$sample_sex == ""))`), whereas `r  length(which(screen$sample_sex == "men"))` and `r length(which(screen$sample_sex == "women"))` comprised only males or females, respectively. Most studies contained samples of adults of all ages `r catg("sample_age", "adults")`. Others reported specific age groups: older adults (n = `r length(which(screen$sample_age == "older adults"))`), younger adults (n = `r length(which(screen$sample_age == "young adults"))`), adolescents (n = `r length(which(screen$sample_age == "adolescents"))`), and children (n = `r length(which(screen$sample_age == "children"))`). Sample characteristics for studies are included in Figure \@ref(fig:samplechar). For a full list of article characteristics, see the appendices (\@ref(tab:studychar))

```{r samplechar, results = 'asis', collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Sample characteristics", fig.height = 8}

# generate a frequency table for the three columnns
samplechar <- c(screen$sample_clinical, screen$sample_clinical2, screen$sample_clinical3)

# remove the row that counted blank spaces
samplechar <- samplechar[-which(samplechar=="")] %>% as.data.frame()

# assign a name to the single column
colnames(samplechar) <- "sample"

# Generate graph
ggplot(data = samplechar, aes(x = fct_infreq(sample) %>% fct_rev())) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Sample characteristics", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
  ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
  ) +
  coord_flip()

```

## Methodological features {#resultsandsynthesis}

### Measures of objective sleep

Objective methods of recording sleep formed two major groups: EEG-based methods and movement-based methods. See Figure \@ref(fig:measures) for number of studies using each method. All movement-based methods involved tri-axial accelerometry through actigraphs or similar devices. PSG was the predominant EEG-based method (n = `r sum(screen$obj_PSG, na.rm=TRUE)`), however a handful of studies used EEG alone, in either single channel (n = `r length(which(screen$obj_EEG_other == "single channel EEG"))`), standard (n = `r length(which(screen$obj_EEG_other == "EEG"))`), or high-definition formats (n = `r length(which(screen$obj_EEG_other == "HD-EEG"))`). A single study used a method of sleep recording that involved recording verbal responses from participants elicited by soft tones played at intervals throughout the night [@espie_1989].

``` {r measures, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Measures of objective sleep", fig.height = 1.0}

df <- data.frame("objective" = c("EEG (including PSG)", "Movement (including actigraphy)"), "count" = c(screen$obj_EEG %>% sum(na.rm=TRUE), screen$obj_movement %>% sum(na.rm=TRUE)))

# Generate graph
ggplot(data = df, mapping = aes(x = objective, y = count)) +
  geom_bar(stat="identity") +
  labs(x = "", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=count),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,170)) +
  coord_flip()
```

#### Polysomnography

Methodological features charted for PSG included scoring criteria, setting, and recording period. See Figure \@ref(fig:scoring) for scoring criteria of included studies.

``` {r scoring, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "PSG scoring methods", fig.height = 2.5}

df <- screen$psg_scoring %>% as.data.frame()

# remove n/a
df <- df[-which(df$. == "n/a"), ] %>% as.data.frame()

# rename some of the entries
df[which(df$. == "SS90-III Sleep Stager System, checked by PSG technologist, coded for 15-min intervals to match diary"), ] <- "SS90-III Sleep Stager System"
df[which(df$. == "not reported"), ] <- "Criteria not reported"

# assign a name to the single column
colnames(df) <- "scoring"

# re-level factors so that "not reported" is last (actually first--will be reversed in the code for the plot)
df$scoring <- factor(df$scoring, levels = c("R&K", "AASM", "Oxford screen scoring method", "R&K and Mendelson", "SS90-III Sleep Stager System", "Criteria not reported"))

# Generate graph
ggplot(data = df, aes(x = scoring %>% fct_rev())) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Scoring Criteria", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
  ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
  ) +
  coord_flip()
```

Methods for scoring PSG were mostly divided between American Academy of Sleep Medicine (AASM) and Rechtschaffen & Kales (R&K) guidelines. Rogers et al [@rogers_reliability_1993] used an automated system for sleep staging, the SS90-III Sleep Stager System (Oxford Medicals, Oxford). Vanable et al [@vanable_sleep_2000] used Mendelson's [@mendelson2012human] guidelines in addition to R&K. Edinger [@edinger_1995] used combined audio and visual criteria for sleep staging [@erwin1989]. Settings for PSG varied and are depicted in Figure \@ref(fig:setting). 

``` {r setting, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "PSG setting", fig.height = 3}

df <- screen$psg_setting %>% as.data.frame()

# remove n/a
df <- df[-which(df$. == "n/a"), ] %>% as.data.frame()

# rename some entries
df[which(df$. == "not reported"), ] <- "PSG setting not reported"
df[which(df$. == "in-lab, home-based"), ] <- "in-lab & home-based"
df[which(df$. == "rest facility"), ] <- "airline rest facility"

# assign a name to the single column
colnames(df) <- "setting"

# capitalise first letter of each row except fMRI
df$setting <- ifelse(df$setting == "fMRI", df$setting, paste0(toupper(substring(df$setting,1,1)), substring(df$setting,2,last = 1000L)))

# re-order factors
df$setting <- factor(df$setting, levels = c("In-lab", "Home-based", "In-lab & home-based", "fMRI", "Airline rest facility", "Truck-berth", "PSG setting not reported"))

# Generate graph
ggplot(data = df, aes(x = setting %>% fct_rev())) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Setting", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
  ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
  ) +
  coord_flip()
```

In-lab and home-based tests comprised the substantial majority of PSG settings with a handful of more unusual settings noted. As for recording periods, PSG most often occurred during the night although a number of alternative periods were noted. See Figure \@ref(fig:period) for a depiction of PSG recording periods.

``` {r period, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "PSG recording period", fig.height = 3}

df <- screen$psg_period %>% as.data.frame()

# remove n/a
df <- df[-which(df$. == ""), ] %>% as.data.frame()

# rename some entries
df[which(df$. == "nocturnal; MSLT"), ] <- "nocturnal & MSLT"

# assign a name to the single column
colnames(df) <- "period"

# capitalise the first letter of each entry
df$period <- paste0(toupper(substring(df$period,1,1)), substring(df$period,2,last = 1000L))

# re-order factors
df$period <- factor(df$period, levels = c("Nocturnal", "MSLT", "24-hour", "Daytime nap", "Nocturnal nap", "In-flight / layover",  "Nocturnal & MSLT", "Repeated naps across 28-hour period"))

# Generate graph
ggplot(data = df, aes(x = period %>% fct_rev())) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Period", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
  ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
  ) +
  scale_y_continuous(limit=c(0,110)) +
  coord_flip()


```

Note, MSLT refers to the multiple sleep latency test.

#### Actigraphy
<!-- ============  text reference hack to generate citations for algorithms ===============-->
(ref:boyne) Actiware [@boyne2013]

(ref:motionware) MotionWare (CamNTech, UK)

(ref:sensewear) SenseWear [@lopez2018]

(ref:gorny) Domino Light [@gorny1996]

(ref:cole) Cole-Kripke [@cole1992]

(ref:kripke) Kripke [@kripke1978]

(ref:sadeh) Sadeh [@sadeh1994]

(ref:barreira) Actiheart [@barreira2009]

(ref:hagheyegh) Fitbit [@jean2001]

(ref:ucsd) UCSD [@jean2001]

(ref:actilife) ActiLife [@peach2014]

(ref:actillume) Actillume [@jean2001]

(ref:mems) Micro-Electro-Mechanical-Systems [@dunne2013]

(ref:ssa) Sleep Sign Act (Kissei Comtec Co, Japan)

(ref:im) IM Systems (Individual Monitoring Systems, Inc., UWA)

(ref:john) Machine Learning Alogrithms [@john2019]

(ref:fatiguescience) Fatigue Science [@russell2000]

(ref:barouni) Barouni [@barouni2020]

(ref:choi) Choi [@choi2011]

(ref:tudorlocke) Tudor-Locke [@tudor2014]

(ref:troiano) Troiano [@troiano2008]

<!-- ============                     end of hack                     ===============-->
We recorded features of actigraphy including device name, scoring algorithm, software, and rest interval definition. See Table \@ref(tab:bigacti) in the appendices for full tabulations of actigraphy characteristics. Actigraphy scoring algorithms are responsible for determining wakefulness and sleep from accelerometer-derived motor activity. Scoring algorithms varied across studies and included (ref:boyne), (ref:motionware), (ref:sensewear), (ref:gorny), (ref:cole), (ref:kripke), (ref:sadeh), (ref:barreira), (ref:hagheyegh), (ref:ucsd), (ref:actilife), (ref:actillume), (ref:mems), (ref:ssa), (ref:im), (ref:john), (ref:fatiguescience), (ref:barouni), (ref:choi), (ref:tudorlocke), and (ref:troiano). The frequencies of these algorithms are depicted in Figure \@ref(fig:algorithms).

```{r algorithms, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Actigraphy algorithms"}

graph <- screen %>% select("acti_algorithm":"acti_algorithm3")

# Function to replace cell values containing Actiware with Actiware

collapseActiware <- function(x) {
  ifelse(grepl("Actiware", x), "Actiware", x)
}

# Apply function to data frame
graph <- apply(graph, c(1,2), collapseActiware)

# Collapse data frame into single vector, generate frequency table, then data frame
graph <- c(graph[,1], graph[,2], graph[,3]) %>% unlist() %>% table() %>% as.data.frame(stringsAsFactors = FALSE)

# Remove the count of blank spaces
graph <- graph[-1, ]

# Replace column names
colnames(graph) <- c("algo", "freq")

# sort ascending by frequency
graph <- graph[order(graph[ ,2], decreasing = FALSE), ]

# rename "not reported"
graph[(graph[ ,1] == "not reported"),1] <- "Algorithm not reported"

# place "not reported" last
graph <- graph %>%
    slice(order(if_else(algo == "Algorithm not reported", 1, 2)))

# Generate graph
ggplot(data = graph, mapping = aes(x = algo, y = freq)) +
  geom_bar(stat="identity") +
  labs(x = "Algorithm", y = "Number of studies") +
  scale_x_discrete(limits=unique(graph$algo)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=graph$freq), position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,60)) +
  coord_flip()

```

Studies using Actiware algorithms varied in their selection of thresholds for scoring wakefulness. These are depicted in Figure \@ref(fig:actiware) below.

```{r actiware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Actiware algorithm threshold settings", fig.height = 3}
acti <- c(screen$acti_algorithm, screen$acti_algorithm2, screen$acti_algorithm3) %>% as.data.frame()

acti <- acti[apply(acti, 1, function(x) grepl("Actiware", x)), ] %>% as.data.frame()

labels = c("All thresholds (Low, Medium, High)", "80 activity counts (High)", "40 activity counts (Medium)", "20 activity counts (Low)", "10 activity counts (Low)", "Actiware wake threshold not reported")

# convert strings to factors
acti[ ,1] <- factor(acti[ ,1], levels = c("Actiware (Low, Medium, High)", "Actiware High (80)", "Actiware Medium (40)", "Actiware Low (20)", "Actiware Low (10)", "Actiware (not reported)"), labels = labels)

colnames(acti) <- "threshold"

ggplot(data = acti, aes(reorder(threshold, -as.integer(threshold)))) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = "Actiware threshold", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
    ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
    ) +
  coord_flip()
```

The rest interval in actigraphy is the period of time where activity is assessed for sleep and is usually intended to coincide with the time the wearer is in bed, attempting to sleep. Information used to define rest intervals varied across reviewed studies and included, singly or in combination, are depicted below in Figure \@ref(fig:intervals).

```{r intervals, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Methods for defining rest intervals in actigraphy"}
#----------------   one-hot encoded rest interval data   ----------------------|

interval <- c("interval_marker",
              "interval_diary",
              "interval_light",
              "interval_activity",
              "interval_external",
              "interval_auto",
              "interval_noreport"
) %>% 
  as.data.frame()
interval["studies"] <- vector()

q = 0

for (x in interval[ ,1]) {
  ref <- which(colnames(screen) == x)
  i <- sum(screen[ref], na.rm = TRUE)
  q <- q + 1
  interval[q ,2] <- i
}

interval[ ,1] <- c("Event marker press",
                   "Sleep diary",
                   "Light sensor",
                   "Manual judgements of activity",
                   "External parameters such as set bed and rise times",
                   "Automatic scoring",
                   "Rest interval not reported")

colnames(interval) <- c("interval", "studies")
#---------------   standard encoding in the "other" column   ------------------|

other <- unique(screen$interval_other)
other <- other[-1] # remove the NA
other <- as.data.frame(other)
other["studies"] <- vector() # add an empty vector

q = 0

for (x in other[ ,1]) {
  i <- length(which(screen$interval_other == x))
  q <- q + 1
  other[q ,2] <- i
}

colnames(other) <- c("interval", "studies")
#------------------------------------------------------------------------------|

interval <- rbind(interval, other)

# sort ascending by frequency
interval <- interval[order(interval[ ,2], decreasing = FALSE), ]

# place "not reported" place last
row_num <- which(interval[ ,1] == "Rest interval not reported")
noreport <- interval[row_num, ]
interval <- interval[-row_num, ]
interval <- rbind(noreport, interval)

# Generate graph
ggplot(data = interval, mapping = aes(x = interval, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "Rest interval", y = "Number of studies") +
  scale_x_discrete(limits=unique(interval$interval)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,70)) +
  coord_flip()
```

The precise combination and order of priority of methods in each study varied markedly. See Table \@ref(tab:bigacti) in the appendices for qualitative descriptions of rest interval approaches across reviewed studies. "Discrepancies queried" indicates that discrepant sleep diary and actigraphy bed and wake times were queried directly with participants and adjusted following discussion.

### Measures of self-report sleep

Self-report sleep measures comprised seven major types. See Figure \@ref(fig:srmeasure) for the number of studies including each of these.

``` {r srmeasure, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Measures of self-report sleep", fig.height = 4}

df <- data.frame("measure" = c(
                               "Sleep diary (including the consensus sleep diary)",
                               "Graphical sleep diary",
                               "Questionnaire on awakening",
                               "Graphical response on awakening",
                               "Interview on awakening",
                               "Pittsburgh Sleep Quality Index (PSQI)",
                               "Habitual sleep questionnaire (other than PSQI)"
                               )
                 , 
                 "studies" = c(
                   sum(screen$subj_diary, na.rm=TRUE), 
                   sum(screen$subj_graph, na.rm =TRUE),
                   sum(screen$subj_morningq, na.rm = TRUE) + sum(screen$subj_postnapq, na.rm = TRUE),
                   sum(screen$subj_postnapgraphq, na.rm = TRUE),
                   sum(screen$subj_morninginterview, na.rm=TRUE + sum(screen$subj_expostwakeinterview, na.rm = TRUE)),
                   sum(screen$subj_PSQI, na.rm = TRUE),
                   sum(screen$subj_otherhabitual, na.rm = TRUE)
                   ),
                 "facet" = factor(c("Sleep diary",
                                    "Sleep diary",
                                    "Query on awakening",
                                    "Query on awakening",
                                    "Query on awakening",
                                    "Habitual sleep questionnaire",
                                    "Habitual sleep questionnaire")
                 )
)

df$facet <- df$facet %>% fct_rev()

ggplot(data = df, aes(x = measure, y = studies)) +
  geom_bar(stat = "identity") +
  scale_fill_grey() +
  labs(x = " ", y = "Number of studies") +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
    ) +
  facet_grid(rows = vars(facet),
             scales = "free_y",
             space = "free_y",
             switch = "y",
             labeller = labeller(facet = label_wrap_gen(width = 10))
  ) +
  scale_y_continuous(limit=c(0,120)) +
  coord_flip()

```

Sleep diaries and questionnaires on awakening were the most common measure of self-report sleep, followed by habitual sleep questionnaires including the Pittsburgh Sleep Quality Index (PSQI)[@buysse1989]. Note, habitual sleep refers to questionnaires that require participants to provide global judgements about their sleep that correspond to a period of time longer than a single night such as a week or a month. Graphical response formats for sleep diaries and questionnaires on awakening required participants to draw their sleep on scales comprising discrete blocks of time. We also recorded whether self-report measures overall attempted to capture habitual sleep or rather *episodic* sleep that occurred night-by-night/episode-by-sleep episode at the same time as objective measures. Results are depicted in Figure \@ref(fig:habitual) below.

``` {r habitual, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Habitual or episodic sleep", fig.height = 1.5}

df <- data.frame("sleep" = c("Habitual sleep", "Episodic sleep", "Habitual and episodic sleep"), "studies" = c(length(which(screen$subj_habitual_desc == "habitual")),
                 length(which(screen$subj_habitual_desc == "matched")),
                 length(which(screen$subj_habitual_desc == "habitual, matched")))
                )
df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = sleep, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,190)) +
  coord_flip()

```

## Sleep variables

A range of variables were used to operationalise sleep discrepancy. These are listed below in Table \@ref(tab:variables) with their usual definitions and equivalent terms.

```{r variables, echo = FALSE}
# Read template table from folder
sleep_variables <- read.csv("../data/sleep_variables.csv")

# Assign 0 to index variable for upcoming loop
q = 0

# Generate empty vector to match length of template table
vec <- vector(length = length(sleep_variables[ ,1]))

# For each variable name listed in the template table...
# search the main dataset for the matching variable
# return the column sum
# store it in the empty vector

for (x in sleep_variables[ ,1]) {
  i <- which(colnames(screen) == x)
  q <- q + 1
  vec[q] <- sum(as.numeric(screen[ ,i]), na.rm = TRUE)
}

# Add new vector to existing template table
sleep_variables <- cbind(sleep_variables, vec)

# Remove the column containing the variable names
sleep_variables<- sleep_variables[ ,-1]

# Rename the columns to something nice
colnames(sleep_variables) <- c("Variable", "Abbreviation", "Calculation", "Equivalent terms", "Studies")

# Add superscript to TWAK for footnote
sleep_variables[which(sleep_variables[ ,2] == "TWAK"),5] <- paste0(sleep_variables[which(sleep_variables[ ,2] == "TWAK"),5], footnote_marker_symbol(1))

# Generate table
kable(sleep_variables[ ,1:4],
      caption = "Sleep variables used for operationalising sleep discrepancy",
      escape = FALSE,
) %>%
  kable_styling(font_size = 10, full_width = FALSE) %>% footnote(footnote_as_chunk = TRUE, general = "Binary sleep-wake involved measuring at one or multiple instances whether a participant's reported sleep state matched the objective sleep state upon which the query was conditional (e.g., participants were only queried during objectively-confirmed sleep). On the other hand, confusion matrix sleep-wake involved measuring at one or multiple instances whether a participant's reported sleep state matched an objective sleep state that was allowed to vary independent of the query (e.g., participants were queried at a certain time point irrespective of sleep state). The states were called so as the former approach produces a binary outcome whereas the latter produces a confusion matrix.", symbol = "TWAK was not used to define sleep discrepancy directly by any of the included studies but is included in the table for clarity")

```

The number of studies that used each sleep variable are depicted below in Figure \@ref(fig:vargraph).

```{r vargraph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Sleep variables"}

# Remove TWAK
df <- sleep_variables[-which(sleep_variables[ ,2] == "TWAK"), ]

# New dataframe from sleep variable table
df <- data.frame(
  "variable" = ifelse(df[ ,2] != "", paste0(df[,1], " (", df[,2], ")"),df[,1]),
  "studies" = as.numeric(df[ ,5])
)

# Rename columns
colnames(df) <- c("variable", "studies")

df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = variable, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "Sleep variable", y = "Number of studies") +
  scale_x_discrete(limits=unique(df$variable)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,220)) +
  coord_flip()

```

The sleep variables TST, SOL, WASO, and SE were most common and formed the majority of identified parameters. Direct sleep-wake agreement was measured by a small subset of studies. Almost all identified sleep variables were measures related to sleep time or awakenings, although we did note some more unconventional parameters listed below separately from the figure above. Allawati et al [@allawati_2021] compared self-report and actigraphic measures of sleep patterns including monophasic, biphasic dawn, biphasic siesta, and polyphasic. Lockley et el [@lockley_comparison_1999], Dautovich et al [@dautovich_subjective_2008], Hanisch et al [@hanisch_sleep_2011], and Nguyen-Michel et al [@nguyen-michel_underperception_2015] reported discrepancy for naps specifically, including variables such as number of naps, number of days napped, mean duration of naps, and total nap time. Baek et al [@baek_2020] and Chan et al [@chan_sleep_2018] compared self-report and actigraphic assessments of variability in TST and other sleep parameters. Thun et al [@thun_actigraphic_2012] compared self-report and actigraphic measures of morningness-eveningness. Finally, McIntyre et al [@mcintyre_2016] investigated self-report-objective discrepancy across a range of sleep behaviours including position at sleep onset, position at wake, number of positional changes, and the presence of leg twitches or jerks. 

### Self-report sleep variable definitions

Calculation of self-report TST, WASO, SE, and TIB varied across studies. Variations across three major types of self-report TST were observed: TST queried directly (e.g., "how many minutes did you sleep last night", TST calculated from other parameters such as TIB, SOL, and WASO, and TST calculated from graphical responses. The results for TST definitions are depicted in Figure \@ref(fig:tstdefinitions) below.

``` {r tstdefinitions, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Self-report TST definitions", fig.height = 4}

# concatenate the two TST type columns into a single vector
vec <- c(screen$subj_TST_t, screen$subj_TST_t2)

df <- data.frame("definition" = c("Direct query",
                                  "TIB--SOL--WASO--TWAK",
                                  "TIB--TWT",
                                  "TIB--WASO",
                                  "FA--LO",
                                  "FWT--SOT",
                                  "SPT--SOL--WASO",
                                  "Calculated (calculation not reported)",
                                  "Graphical responses",
                                  "Not reported"),
                 "studies" = c(grepl("question", vec) %>% which() %>% length(),
                               length(which(vec == "TIB-SOL-WASO-TWAK")),
                               length(which(vec == "TIB-TWT")),
                               length(which(vec == "TIB-WASO")),
                               grepl("LO-FA", vec) %>% which() %>% length(),
                               length(which(vec == "FWT-SOT")),
                               length(which(vec == "SPT-SOL-WASO")),
                               length(which(vec == "calculated (not reported)")),
                               length(which(vec == "visual")),
                               length(which(vec == "not reported"))
))

df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = definition, y = studies)) +
  geom_bar(stat="identity") +
  scale_x_discrete(limits=unique(df$definition)) +  # This keeps the order of the data frame
  labs(x = "Variable definitions", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,130)) +
  coord_flip()

```

Note, FA--LO indicates lights off to final awakening. By conventional definitions of SPT, SPT--SOL--WASO is equal to TIB--SOL--WASO--TWAK, but is listed separately above to reflect differences in terminology. Definitions for WASO also varied and these are depicted in \@ref(fig:wasodef) below.

``` {r wasodef, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Self-report WASO definitions", fig.height = 3}

df <- data.frame("definition" = c("Direct query", "TIB-TST-SOL", "Number of awakenings * average length of awakenings", "Calculated (not reported)", "Graphical responses", "Definition not reported"), "studies" = c(
  grepl("direct question", screen$subj_waso) %>% which() %>% length(),
  length(which(screen$subj_waso == "TIB-TST-SOL")),
  length(which(screen$subj_waso == "number of awakenings multiplied by average length of awakenings")),
  length(which(screen$subj_waso == "calculated (not reported)")),
  length(which(screen$subj_waso == "visual")),
  length(which(screen$subj_waso == "not reported"))
))
  

df[which(df[ ,1] == "TIB-TST-SOL"),1] <- "TIB--TST--SOL"

# Reverse order of df before ggplot reverses it again
df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = definition, y = studies)) +
  geom_bar(stat="identity") +
  scale_x_discrete(limits=unique(df$definition)) +  # This keeps the order of the data frame
  labs(x = "Variable definitions", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,50)) +
  coord_flip()

```

Definitions for self-report TIB used in operationalising sleep discrepancy are depicted Figure \@ref(fig:tibdef).

``` {r tibdef, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Self-report TIB definitions", fig.height = 2.5}

df <- data.frame(
  "definition" = c("RT--LO",
                   "FA--LO",
                   "TST + WASO + SOL",
                   "Graphical responses",
                   "Direct query",
                   "Definition not reported"), 
"studies" = c(
  length(which(screen$subj_tib == "LO-RT")),
  length(which(screen$subj_tib == "LO-FA")),
  length(which(screen$subj_tib == "TST+WASO+SOL")),
  length(which(screen$subj_tib == "visual")),
  length(which(screen$subj_tib == "direct question")),
  length(which(screen$subj_tib == "not reported"))
))
  
df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = definition, y = studies)) +
  geom_bar(stat="identity") +
  scale_x_discrete(limits=unique(df$definition)) +  # This keeps the order of the data frame
  labs(x = "Variable definitions", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,50)) +
  coord_flip()

```

Note, RT--LO refers to the time between lights off and rise time. SE was almost unanimously calculated as TST/TIB\*100 , although varying definitions for the TST and TIB components affect this outcome. One study [@neu_sleep_2007] used two definitions of SE, one comprising TST/TIB and the other TST/sleep period time (SPT).

### Objective sleep variable definitions

Objective TST was defined very consistently with the exception of Sinclair et al [@sinclair_2014] who, in addition to providing a standard definition for TST, measured TST across a 24-hour period, such that time spent asleep outside the usual nocturnal period (i.e., naps) contributed to this measurement. Objective definitions for SOL varied considerably and these are depicted in Figure \@ref(fig:SOL) below.\

```{r SOL, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.cap = "SOL definitions"}
#-------------------------------- SOL Bar Plot --------------------------------|

sol <- c(screen$obj_SOL_t,
                screen$obj_SOL_t2,
                screen$obj_SOL_t3,
                screen$obj_SOL_t4)


df <- table(sol) %>% as.data.frame

colnames(df) <- c("sol", "studies")

# delete row containing NA
df <- df[-which(df$sol==""), ]

# capitalise first letter of each row
df$sol <- paste0(toupper(substring(df$sol,1,1)), substring(df$sol,2,last = 1000L))

# sort ascending by frequency
df <- df[order(df[ ,2], decreasing = FALSE), ]

# rename some columns
df[which(df$sol == "Not reported"), 1]  <- "SOL definition not reported"
df[which(df$sol == "First epoch of any sleep stage"), 1]  <- "First epoch of any sleep stage (standard AASM)"

level_order <- c(
  "Actigraphy-defined",
  "First epoch of any sleep stage (standard AASM)",
  "First 3 consecutive epochs of stage 1 or first epoch of any other sleep (R&K)",
  "First epoch Stage 2",
  "First 20 consecutive epochs any stage of sleep (LPS)",
  "First sleep spindle",
  "First epoch Stage 1",
  "First epoch SWS",
  "First 3 consecutive epochs of sleep",  
  "First 2 consecutive epochs of Stage 2",
  "First 10 consecutive epochs Stage 2",
  "First Stage 2 interrupted by no more than 4 epochs of wake or Stage 1 within 20 epochs",
  "First 20 epochs of sleep containing no more than 4 epochs of wake time, Stage 1 sleep, or movement time",
  "First 20 epochs of Stage 2 or SWS without intervening period of >4 epochs Stage 1 or wakefulness",
  "Video observation",
  "Parameter varied in model",
  "SOL definition not reported"
) %>% rev()

# Generate graph
ggplot(data = df, mapping = aes(x = sol, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "SOL definition", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  scale_y_continuous(limit=c(0,80)) +
  scale_x_discrete(limits=level_order) +
  coord_flip()

```

Note that SWS = slow wave sleep, LPS = latency to persistent sleep, AASM = American Academy of Sleep Medicine guidelines, R&K = Rechstaffen & Kales guidelines. Parameter varied in model indicates that the definition of sleep onset was varied within the context of a predictive model. Among PSG studies, the two most common approaches were dependent on standard definitions provided by the R&K [@rechtschaffen1968] and AASM [@berry2012aasm] scoring guidelines.

Most studies used standard PSG or actigraphy criteria for defining objective number of awakenings (i.e., a single epoch of wakefulness). A single exception was Lewis et al [@lewis_1969], who stipulated that a period last over a minute to count as an awakening. Neu et al [@neu_sleep_2007] used the same definitions for objective SE as they did for self-report SE. 

### Sleep quality

Sleep quality discrepancy was measured by `r onehot("sleep_quality_measured", brackets=FALSE)` studies using (on the self-report side) sleep quality ratings `r catg("subj_sleep_sq_class", "index")`, PSQI total scores `r catg("subj_sleep_sq_class", "PSQI scores")`, sleep quality factor scores `r catg("subj_sleep_sq_class", "factor score")`, sleep depth ratings `r catg("subj_sleep_sq_class", "sleep depth rating")`, or sleep quality composite scores `r catg("subj_sleep_sq_class", "composite score")`. On the objective side, sleep quality measures included SE `r  catg("obj_sq_equiv_class", "SE")`, factor scores from sleep variables `r catg("obj_sq_equiv_class", "factor score")`, sleep architectural variables `r catg("obj_sq_equiv_class", "SE")`, N3 sleep quantity `r catg("obj_sq_equiv_class", "N3 sleep")`, TWT `r catg("obj_sq_equiv_class", "TWT")`, and a composite variable formed from SOL, WASO, and SE `r catg("obj_sq_equiv_class", "composite variable")`. Although approaches varied substantially, the most common combination of sleep quality measures was a sleep quality rating and SE.

## Method of handling repeated measurements

Sleep data often involves repeated measurements of the same individual. Actigraphy and sleep diaries usually involve data collection across 7 to 14 days and multiple consecutive nights of PSG are sometimes recorded. Methods for handling repeated measurements are depicted below in Figure \@ref(fig:methodrm)

``` {r methodrm, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 10, fig.cap = "Methods for handling repeated measurements"}

df <- data.frame(
  "methods" = c("Mean values", "Modal values", "Median values",  "Means of derived indices", "Standard deviations of derived indices", "Repeated measures ANOVA", "Linear mixed models", "Generalised estimating equations", "Structural equation modelling", "Repeated measures correlation", "Pooled observations", "Separate analyses", "Single recording instance"),
  "studies" = c(
    sum(screen$rm_mvalues, na.rm = TRUE),
    length(which(screen$rm_other == "median values")),
    grepl("modal values", screen$rm_other) %>% which() %>% length(),
    sum(screen$rm_mindices, na.rm = TRUE),
    grepl("standard deviation", screen$rm_other) %>% which() %>% length(),
    sum(screen$rm_rmANOVA, na.rm = TRUE),
    sum(screen$rm_lmm, na.rm = TRUE),
    grepl("generalised estimating", screen$rm_other) %>% which() %>% length(),
    grepl("structural equation", screen$rm_other) %>% which() %>% length(),
    grepl("repeated measures correlation", screen$rm_other) %>% which() %>% length(),
    sum(screen$rm_pool, na.rm = TRUE),
    sum(screen$rm_separate, na.rm = TRUE),
    sum(screen$rm_singlenight, na.rm = TRUE)
    ))
    
df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = methods, y = studies)) +
  geom_bar(stat="identity") +
  labs(x = "Method of handling repeated measurements", y = "Number of studies") +
  scale_x_discrete(limits=unique(df$methods)) +  # This keeps the order of the data frame
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  coord_flip()




```

Note that pooled observations involved collapsing data across multiple instances of recording. Separate analyses indicate that analyses were conducting separately for each instance of recording. In addition to the above, some studies measuring naturalistic sleep in the home environment took day of week into consideration for analyses. `r (catg("weekend", "weighted average", brackets = FALSE) + catg("weekend2", "weighted average", brackets = FALSE)) %>% english %>% str_to_title()` studies calculated a weighted average for sleep variables equal to 5/7* (mean weekday sleep) + 2/7* (mean weekend sleep), and `r (catg("weekend", "split", brackets = FALSE) + catg("weekend2", "split", brackets = FALSE)) %>% english()` performed analyses for weeknights and weekends separately.

## Direct comparisons of self-report and objective sleep

A total of `r onehot("aim_agreement", brackets=FALSE)` studies measured sleep discrepancy at the group level by directly comparing self-report and objective sleep. Methods for achieving this varied and are depicted below in Figure \@ref(fig:group)

```{r group, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Statistical methods for comparing self-report and objective sleep"}

group_variables <- read.csv("../data/group_variables.csv")

# Assign 0 to index variable for upcoming loop
q = 0

for (x in group_variables[ ,1]) {
  i <- which(colnames(screen) == x)
  q <- q + 1
  group_variables[q, 3] <- sum(screen[ ,i], na.rm = TRUE)
}

group_variables$variable_name <- factor(group_variables$variable_name, levels = group_variables$variable_name)

# order ascending
group_variables <- group_variables[order(group_variables[ ,3], decreasing = FALSE), ]

# rename not reported and bring to top of data frame
row_num <- which(group_variables[ ,2] == "Other direct comparison (described below)")
other <- group_variables[row_num, ]
group_variables <- group_variables[-row_num, ]
group_variables <- rbind(other, group_variables)

ggplot(data = group_variables, aes(x = variable_name, y = studies)) +
  geom_bar(stat="identity", position="dodge") +
  labs(x = "Methods for direct sleep comparisons", y = "Number of studies") +
  theme(legend.position = "none") +
  scale_fill_grey() +
  scale_y_continuous(limit=c(0,110)) +
  scale_x_discrete(limits=unique(group_variables$variable_name)) +  # This keeps the order of the data frame
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.25) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  )+
  coord_flip()

```

Note, Bland Altman analyses include Bland Altman plots and the reporting of 95% limits of agreement [ @blandaltman1999]. Pitman's test (also known as the Pitman-Morgan test) is a test of differences of variances between dependent samples [@pitman1939; @morgan1939] and was used to compare the variability of self-report and objective sleep. 
One-sample *t*-tests of difference scores are equivalent to paired *t*-tests but are included separately in the figure to reflect differences in reporting. Classification performance measures include percentage agreement, accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). Formulae used for the intra-class correlation coefficient varied across studies. Spearman correlations and Wilcoxon Signed Rank Tests were often used to handle the skew of variables such as SOL and WASO. Other methods included the delta coefficient [@girschik_2012], partial correlation and factor analysis [@regestein_2004], errors-in-variables regression [@lauderdale_2008], repeated measures correlation [@gibson_2023], non-parametric limits of agreement [@thurman_2018], survival agreement [@guedes_2016], latent correlations for testing associations at within-subjects and between-subjects level [@fengsvetnik_2018], and structural equation modelling [@friedmann_2022].

## Methods for investigating the relationship of sleep discrepancy with other variables

A total of `r onehot("aim_construct", brackets=FALSE)` studies aimed to investigate the relationship of sleep discrepancy with other variables of interest. Most studies achieved this by operationalising sleep discrepancy on the individual level through the calculation of a derived index.

### Derived indices

Approximately half `r onehot("index_present")` of included studies calculated a derived index (e.g., self-report TST--objective TST) to operationalise sleep discrepancy. Some studies used indices directly in statistical analyses `r catg("index_groups", "0")` whilst others used indices to divide samples into groups (n =`r length(which(screen$index_groups == "binary")) + length(which(screen$index_groups == "trichotomy"))`) either dichotomising `r catg("index_groups", "binary")` or trichotomising `r catg("index_groups", "trichotomy")` derived score values. Methods for deriving indices varied across studies and can be broadly categorised into four groups: arithmetic difference scores, where one measure is simply subtracted from the other (e.g., sTST--oTST); absolute difference scores, composed of the absolute value of algebraic difference scores (e.g., \|sTST--oTST\|); ratio scores, when one measure is divided by the other (e.g., sTST/oTST); and combination scores that incorporate both subtraction and division of component measures (e.g., oTST--sTST/oTST). A list of indices including the number of studies that used them are provided in Figure \@ref(fig:derived) below.

```{r derived, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Derived indices used for operationalising sleep discrepancy", fig.height = 8, fig.width = 9}

#------------------------   Derived indices plot   ----------------------------|

codebook <- read.csv("../data/derived_variables.csv")

derived <- c(screen$index1,
             screen$index2,
             screen$index3,
             screen$index4,
             screen$index5,
             screen$index6,
             screen$index7,
             screen$index8) %>% as.factor() 
derived <- derived[-which(derived=="")] %>% as.data.frame()

# ----   Find variable information from variable codes  ----
q = 0 # Assign 0 to index variable for upcoming loop

for (x in derived[ ,1]) {
  i <- codebook[which(codebook[ ,1] == x), 2:4]
  q <- q + 1
  derived[q,2:4] <- i
}

# store order for facets
facet_order <- c("Arithmetic difference scores",
                 "Absolute difference scores",
                 "Ratio scores",
                 "Combination scores",
                 "")

# convert strings to factors (necessary for facet_grid)
derived[ ,2] <- factor(derived[ ,2], levels = facet_order)

ggplot(data = derived, aes(x = reorder(variable_name, variable_name, function(x)length(x)))) +
  geom_bar() +
  scale_fill_grey() +
  labs(x = " ", y = "Number of studies") +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position=position_dodge(width=0.9),
    hjust=-0.5,
    size=3.25
    ) +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted"),
    strip.placement = "outside"
    ) +
  facet_grid(rows = vars(variable_group),
             scales = "free_y",
             space = "free_y",
             switch = "y",
             labeller = labeller(variable_group = label_wrap_gen(width = 10))
  ) +
  coord_flip()

```

Overall, the sleep variables TST, SOL, and WASO represented the substantial majority of derived indices. Arithmetic difference scores were the most common derived index and with these objective sleep was subtracted from self-report sleep considerably more often than vice-versa. By contrast, ratio scores did not differ in directionality, and all that were recorded featured self-report sleep as the numerator and objective sleep as the denominator. Absolute differences are unique amongst derived indices for operationalising negative sleep discrepancy as equal to positive sleep discrepancy. With the relatively few absolute difference scores noted here it appears that the literature has mostly conceived of sleep discrepancy as a directional concept. All the combination scores identified followed the general format of an arithmetic difference score divided by a component of the difference.

A handful of more atypical derived scores were identified. Jackowska et al [@jackowska_psychosocial_2011] created a sleep quality discrepancy index by subtracting a z-transformed self-report sleep quality rating from z-transformed objective SE. Kay et al [@kay_variability_2013] derived a nightly variability index for sSOL--oSOL and sWASO--oWASO by dividing intra-individual standard deviations by the sample-wise standard deviation for each variable. Mendelson et al [@mendelson_1986] divided self-report sleep following experimental awakenings by objective sleep following experimental awakenings. Winer et al [@winer_tau_2021] derived a difference score from subtracting composite scores composed of the average of z scores of TST, SE, and sleep fragmentation (number of awakenings/SPT\*100) from z-transformed PSQI total scores.

### Other methods for operationalising sleep discrepancy {#altdisc}

A number of other ways to characterise the relationship of sleep discrepancy with other variables of interest were identified and are depicted in Figure \@ref(fig:otherm) below. Some studies operationalised sleep discrepancy using an interaction term within an ANOVA or other linear model such that the other variable(s) of interest was/were instantiated as the moderator of the relationship between self-report and objective sleep. Others used percentage agreement for sleep or other classification performance metrics in subsequent statistical analyses with other variables. Differences between correlations amongst self-report and objective sleep between groups were also tested with bootstrapped confidence intervals [@jackson_2018, @jackson_2020], or the Fisher transformation [@defrancesco_2021]. studies operationalised sleep discrepancy with the Sleep Fragment Perception Index (SFPI), an index that exploits the fact that longer sleep fragments are more likely to be identified as sleep by individuals than shorter fragments [@hermans_modeling_2020]. The SPFI is a parameter modelled to assume the shortest length of objective sleep that is perceived as subjective sleep. For the SFPI, a higher value corresponds to a longer sleep fragment necessary for subjective awareness of sleep and hence greater sleep discrepancy.

``` {r otherm, collapse = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Other methods for operationalising sleep discrepancy", fig.height = 2.0}

# Create data frame with each one-hot encoded column
df <- data.frame("method" = c("Interaction", "Classification performance in statistical analysis", "Differences between correlations", "Modelled parameter"),
                 "studies" = c(
                   sum(screen$construct_interaction, na.rm=TRUE),
                   sum(screen$construct_agreeinstat, na.rm=TRUE),
                   sum(screen$construct_corrdiff, na.rm=TRUE),
                   sum(screen$construct_modelling, na.rm=TRUE)
                 )
)

# Reverse order of data frame as ggplot will reverse it again
df <- df[rev(rownames(df)),]

# Generate graph
ggplot(data = df, mapping = aes(x = method, y = studies)) +
  geom_bar(stat="identity") +
  scale_x_discrete(limits=unique(df$method)) +  # This keeps the order of the data frame
  labs(x = "Method", y = "Number of studies") +
  theme(
    legend.position = "none",
    panel.background = element_rect(fill = "transparent", colour = "grey"),
    panel.border = element_rect(fill = NA, colour = "grey"),
    panel.grid = element_line(colour = "grey", linewidth = 0.2, linetype = "dotted")
  ) +
    scale_y_continuous(limit=c(0,12)) +
  geom_text(aes(label=studies),position=position_dodge(width=0.9), hjust=-0.5, size=3.00) +
  coord_flip()



```

## Miscellaneous methodological features

Lastly, we recorded some other methodological features of studies that appeared pertinent to the study of sleep discrepancy. `r onehot("misc_cbti", brackets = FALSE) %>% english() %>% str_to_title()` studies investigated sleep discrepancy during, as a predictor of response to, or as an outcome of, cognitive behaviour therapy for insomnia (CBT-I). `r onehot("misc_exp_awakenings", brackets = FALSE) %>% english() %>% str_to_title()` studies used an experimental awakening paradigm where participants were monitored in-lab and woken by sound probes or technician interventions. A total of `r onehot("aim_validation", brackets = FALSE)` studies were conducted with the aim of validating or assessing a particular sleep instrument.

<!-- ========================================================================================================================================== -->
<!-- ===========================================================     DISCUSSION     =========================================================== -->
<!-- ========================================================================================================================================== -->

# Discussion {#item19}

This study systematically reviewed ways of measuring, conceptualising, and analysing sleep discrepancy. Studies varied considerably across the broad range of recorded methodological characteristics and the number of studies identified indicated a vast literature. At the level of measurement, objective sleep mostly consisted of polysomnography and actigraphy, whilst self-report sleep spanned a range of questionnaires and diaries of varying response formats. Within objective sleep measures, approaches varied according to setting, equipment, and algorithms and procedures to process data. Sleep time-related metrics (e.g., TST, SOL, WASO) preponderated in the identified studies, with a small minority measuring direct sleep-wake agreement and a handful of studies measuring other sleep-related features or behaviours. Sleep quality was also investigated by a small number of studies. Definitions for sleep variables themselves did vary across studies although mainly on the self-report side and principally for the variables TST, WASO, and TIB, although objective SOL varied considerably. At the level of data processing and analysis, a range of strategies were employed to accommodate repeated measurements but for many studies, too, there was a single instance of recording. Direct comparisons were commonly made between self-report and objective sleep and these spanned a number of statistical approaches. Many studies went further than comparing self-report and objective sleep directly and attempted to investigate the relationship between sleep discrepancy and other variables. This was achieved most often with derived indices (e.g., self-report TST--objective TST), although other strategies were also employed. Our findings are discussed below with recommendations for further research where relevant.

## Methodological diversity in sleep discrepancy research represents a conceptual problem

In attempting to measure the discrepancy between two concepts it is useful to know the discrepancy---or variability---within each concept itself. This is so that it can be certain that the discrepancy being measured cannot be accounted for by the amount of variation within each concept. Our results indicate that "self-report sleep" or "objective sleep" are not monolithic entities but variegated in ways that may be important. Take, for example, the simplest methodological distinction in objective sleep measurement: polysomnography versus actigraphy. In comparison with PSG, actigraphy generally overestimates sleep and underestimates wake time, and can have trouble distinguishing sleep from quiescent periods of wakefulness [@marino2013]. These trends have been observed to be greater for samples experiencing chronic medical or psychiatric conditions [@conley2019agreement]. Tryon [@tryon2004] has emphasised that these differences between polysomnography and actigraphy are systematic, rather than random, and it follows from this that the two forms of objective sleep measurement will form distinct kinds of sleep discrepancy.

This issue continues through finer methodological distinctions. For example, within actigraphy, estimation of sleep can vary substantially across the various scoring algorithms identified in this review. There is ample evidence indicating that the concordance of actigraphy to PSG by algorithm can vary according to the sample in question [@gao2022actigraphy;@desouza2003; @quante2018actigraphy; @haghayegh2019] and algorithm performance can even vary based on the actigraph device used [@kripke2010wrist]. A further example can be represented by the sheer range of sleep variables available to operationalise sleep discrepancy. Discrepancy within each variable is likely to have a distinct theoretical meaning. For example, Castelnovo et al [@Castelnovo2019] noted that little overlap was found between individuals that misperceive TST and misperceive SOL. Important distinctions continue even within sleep variables themselves. We identified a range of self-report TST definitions, with the most common being direct queries (e.g., "how many hours did you sleep last night?") and calculated parameters (e.g., TST = TIB--SOL--WASO--TWAK). Alameddine et al [@alameddine_2015] compared these two definitions and found that calculated estimates tended to exceed those from direct queries. TST discrepancy was overall negative across their sample for those with and without insomnia and so it is possible that indirect queries produce self-report TST that is closer to objective estimates.

For each of these examples, there are differences in sleep discrepancy across methodological approaches that evidence indicates is likely to be systematic. This is a significant issue for studies investigating the relationship between sleep discrepancy and another construct as the variance accounted for by the span of possible approaches may well exceed that of the effect the researchers are looking for. Addressing this issue may take a number of approaches. A stronger research focus on methods, investigating the impact of changes in methodology would be helpful overall. Specific tools such as structural equation modelling could be used to account for the variance represented by various methodological choices alone or in relation to other constructs. Theoretical justification or some rational account should also be provided for selection of sleep variables where possible, as many are likely to be conceptually distinct. A standardised approach to conducting and scoring actigraphy would reduce methodological variance in this particular area.

## Methodological diversity may influence the rate of false-positive findings

Methodological diversity may also have consequences on the rate of false-positives in the sleep discrepancy literature. The term *researcher degrees of freedom* has been used to refer to the range of possible decisions throughout the data collection and analysis process that can be exploited to yield tests that reach statistical significance [@simmons2011]. As evidenced by this review, the amount of researcher degrees of freedom in sleep discrepancy research is considerable, particularly at the data analysis stage, and especially for sleep variable definition and selection. Any combination of the large number of sleep variables identified in this review may be chosen as an alternative analytic decisions during analysis. When the different possible definitions of each of these variables are also enumerated, the number of possible decisions seems endless. Note, this issue is not confined to the case of a researcher deliberately exploring analytical alternatives following a null result. In a problem referred to as the garden of forking paths [@gelman2013], any methodological decision made in response to an observed feature of the data increases the likelihood that findings will be misleading. An example of this would be selecting SE over TST for a subsequent analysis after observing that SE discrepancy best discriminated individuals with and without insomnia. Even though the eventual result is at this point unknown, the decision of sleep variable is contingent on the data, and ultimately, *p*-values will not reflect what would have happened had TST been chosen instead. For any study investigating the relationship of sleep discrepancy with other constructs, pre-registration of hypotheses and plans for data collection and analysis [@nosek2018] is likely to be helpful in minimising inflated Type I error through post-hoc methodological decisions.

## Definitions of objective sleep onset latency are multifarious and mostly arbitrary {#sol}

Definitions of objective SOL vary considerably in the sleep discrepancy literature. Self-report sleep onset is more likely to coincide with the occurrence of the first sleep spindle, an EEG waveform associated with stage 2 sleep, than with the first incidence of stage 1 sleep [@bonnetmoore_1982]. As such, R&K SOL is likely to have greater correspondence to self-report SOL than AASM SOL. This disparity would be expected to increase with greater sleep fragmentation in the early sleep period and substantial differences in AASM and R&K sleep discrepancy should be expected in samples with disrupted initial sleep. Stricter/longer SOL definitions including the Latency to Persistent Sleep (LPS) [@bianchi_sleep_2012] and complex definitions from Means et al [@means_2003] and Lehrer et al [@lehrer_2022] are expected to have the closest correspondence to self-report SOL, as research indicates 22-minutes of uninterrupted sleep is needed for healthy adults to perceive a bout of sleep during the beginning of the night [@hermans_sleep_2020]. 

Sleep onset is a continuous process for which it is difficult to identify a clear start-point [@tryon2004]. For example, with PSG scored by AASM criteria, 50% of a 30-second epoch is needed to exhibit sleep for the scoring of a first sleep stage. This means sleep latency is defined as the number of epochs preceding the first uninterrupted \~16 seconds of an EEG depicting activity consistent with sleep. An individual could conceivably achieve this 16-second threshold within two minutes, wake up, and not return for another two hours (SOL = 2 minutes). Equally, an individual could spend a two hour period getting 14-second blocks of sleep before achieving a consolidated bout of sleep (SOL = 120 minutes). These are extreme examples, but they highlight the difficulty with defining a single point of sleep onset. Of course, a line needs to be drawn somewhere, but the position of this line appears to be an arbitrary decision.

Saline et al [@saline_sleep_2016] noted another problem although only for studies that investigate both TST and SOL concurrently. In the estimation of TST, individuals may attempt to judge the length of time between their subjective sleep onset and final wake time---anchoring their TST estimate to their SOL estimate. In measuring TST and SOL discrepancy, SOL discrepancy is thus being tested for twice: once in SOL and again implicitly in TST. Their solution to this problem was to obtain independent measurements by estimating the amount of objective sleep measured during the subjective sleep latency period (sleep during subjective latency; SDSL) and the amount of objective sleep measured following the subjective sleep latency period (latency adjusted total sleep time; LA-TST).

In view of these issues, three options are recommended in the context of sleep discrepancy research. The first is to proceed with defining objective SOL using latency to persistent sleep (LPS)---the first 20 consecutive epochs of sleep. Due to the considerable time it takes to perceive a bout of sleep and the rarity and limited magnitude of SOL underestimation [@saline_sleep_2016; @hermans_sleep_2020] it makes sense to use a longer criterion than a shorter one. LPS also has the advantage of being simpler than many of the alternatives we identified. The second option is to use SDSL for the reasons described in the previous paragraph. It should be noted, however, positive discrepancy (i.e., SOL underestimation) is not measurable with this method. The third option is to avoid SOL as a sleep variable and to model sleep perception parameters during the sleep onset period according to Hermans et al [@hermans_sleep_2020]. The latter two options have the added advantage of operationalising sleep discrepancy without the use of derived scores---the problems with which are discussed briefly in a following paragraph.

## Sleep discrepancy is mostly restricted to sleep states or sleep time and varies in its conceptual distance to sleep misperception {#misp}

To map the boundaries of the concept of sleep discrepancy, we included any studies comparing objective sleep with an equivalent measure of self-report sleep. From the very few studies identified investigating sleep patterns or other sleep-related behaviours it appears that sleep discrepancy is mostly restricted to discordance in sleep states (e.g., wakefulness versus sleep) or discordance in sleep time parameters (e.g., total sleep time). It may be helpful to consider sleep discrepancy, as so defined, in relationship to sleep misperception. These two terms have been used interchangeable in the past and the problems with doing this have been noted by a number of authors [@Moul2004; @tryon2004]. Stated simply, sleep is a complex process for which there no one perfectly valid measure, and using the term *sleep misperception* brings a status to objective measures of sleep that may not be warranted. For example, sleep-like EEG activity can occur during waking consciousness in a phenomenon known as local sleep [@krueger2019local], and other dissociations between the EEG and sleep-related physiological processes, have been observed under some conditions [@krueger2013sleep]. Moreover, conventional sleep scoring is but one way of classifying EEG data and subtler systems exist, including the cyclic alternative pattern [@Parrino2012].

Whilst it may not be possible to directly measure sleep misperception for these reasons, sleep discrepancy can be closer or further to sleep misperception conceptually depending on its operational definition. Closest are studies measuring sleep-wake agreement or classification using EEG under laboratory conditions. In a case where a participant who, being asleep for five minutes, is woken by a technician and reports complete wakefulness for the preceding period, only the fallibility of objective recording can account for a conceptual distinction between sleep discrepancy and true sleep-state misperception. This fundamental sleep discrepancy represented by direct sleep-wake agreement can be contrasted with sleep discrepancy represented by sleep time variables (e.g., TST, SOL). Moving from sleep-wake agreement to sleep time variables introduces additional factors that may account for the incongruence between self-report and objective sleep and hence provides a broader definition of sleep discrepancy. On the objective side, PSG potentially introduces artefact from transient (e.g., \<15 second) awakenings [@smith2000] and the arbitrary nature of SOL definitions (see section \@ref(sol)). Actigraphy introduces the potential for immobile wake to be scored as sleep [@desouza2003; @paquet2007] and variance contributed by methodological factors such as choices in scoring algorithms. On the self-report side, sleep diaries and questionnaires introduce memory or reporting biases [@clegg2023real] as potential factors contributing to sleep discrepancy. See Harvey et al [@Harvey2012] for a discussion of these factors in the context of insomnia. In the present review, we reported a key distinction between *habitual* and *episodic* measures of self-report sleep.

Moving from episodic to habitual measures broadens the concept of yet sleep discrepancy further. A more global sleep discrepancy may be represented by comparisons of habitual self-report sleep with aggregated objective sleep (e.g., mean sleep variables values across 14 nights of actigraphy), the underlying processes for which are likely different to those of individual nights. Where habitual self-report sleep is compared to objective estimates spanning one to a few nights, intra-individual variation in sleep patterns is introduced to sleep discrepancy. In other words, some component of the difference between objective and self-report sleep can be accounted for by the difference between habitual sleep and the circumstances of testing---which may be substantial. If the objective measure is PSG, effects of the laboratory/testing environment (i.e., the first night effect[@Agnew1966; @newell2012one]) are additionally introduced.

## Derived indices are common and the use of these as an operational measure of sleep discrepancy is problematic {#dvar}

Derived variables, including difference scores and ratio scores, are overwhelmingly the most common way of operationalising sleep discrepancy to investigate its relationship with other variables. The use of derived variables for such a purpose is associated with a range of conceptual and methodological problems [@Cronbach1970; @edwards2002; @Kronmal1993] that are severe enough to warrant discontinuing their use in sleep discrepancy research. Stated briefly, in a relationship with another variable, the effect of each component of a derived index (e.g., a difference score representing the subtraction of self-report from objective TST) is confounded such that it is not possible to determine whether self-report sleep, objective sleep, or some combination of the two are driving the relationship [@edwards2002]. Moreover, derived scores impose inappropriate constraints on relationships between other variables that are often not entailed by, or else completely contradictory to, stated hypotheses [@edwards2002]. A large range of derived variables were identified by this review, none of which escape the problems described by the aforementioned authors. Fortunately, a number of alternative strategies for characterising relationships between sleep discrepancy and other constructs are available. Such methods identified in this review included using classification performance metrics within conventional statistical analyses, representing sleep discrepancy with moderation/interaction effects, and modelling sleep discrepancy parameters mathematically.

## Averaging sleep variables across multiple nights is a common practice and can cause problems

In the studies identified in this review, the most common way of handling repeated measurements of sleep variables was by averaging across multiple instances of recording. This technique is problematic when applied to concurrent nightly/episodic measurements of self-report and objective sleep as it relies on the assumption that patterns of sleep over/underestimation are consistent across nights. Extreme positive and negative sleep discrepancy occurring alternately on successive nights could result in averages denoting negligible discrepancy. This may be a realistic concern for research in sleep discrepancy and insomnia, for example. Although most individuals with insomnia tend to underestimate sleep, high inter-night variability is observed and some individuals will overestimate sleep [@trajanovic_2007, @telindert_2020]. An exception to this problem exists in the case of comparing aggregated objective sleep against a habitual measure of self-report sleep, such as the PSQI. Here, using means or medians to determine habitual measures of objective sleep is necessary to define sleep discrepancy at the habitual, rather than the nightly level. In other cases, linear mixed models, generalised estimating equations, and structural equation models were methods identified in this review that do not inherit the same problems with averaging across repeated measures.

## Correlations have sometimes been used inappropriately as a measure of concordance

Despite being the most common approach to comparing self-report and objective sleep measures, Pearson or Spearman correlations are broadly inappropriate for the characterisation of agreement or discrepancy. Correlation is strictly a measure of association between two variables and is insensitive to systematic error between measures [@liu2016]. For example, the same correlation coefficient may equally describe a sample where self-report and objective estimates of sleep tend to be equal as one where (i), objective estimates tend to exceed self-report estimates by a given constant (e.g., two hours) or (ii), the value of objective sleep varies proportional to the level of self-report sleep. Measures of agreement including Bland-Altman analyses, intra-class correlation, and Lin's concordance coefficient were also used by a large number of studies and are preferable for the measurement of discrepancy in equivalent parameters.

## Sleep quality discrepancy is conceptually unclear

Sleep quality discrepancy was measured by a small number of studies in this review, according to varying strategies. Sleep quality discrepancy is a difficult topic for two reasons. First, there is no consensus approach to operationalising sleep quality. A recent review of methods for measuring sleep quality identified an immense range in strategies, especially for objective measures[@mendoncca2019review]. Second, there are no clear self-report analogues for objective measures of sleep quality, or vice-versa. An individual is unable to directly estimate their number of EEG arousals, quantity or proportion of N3 sleep, or other features of sleep macro or microstructure unavailable to consciousness. Equally, it is not clear how to compare a sleep quality rating judgement (e.g., on a Likert scale) with objective measures (see Krystal & Edinger [@krystaledinger2008]). Overall, investigating the relationships of sleep quality discrepancy to other variables is unlikely to be profitable until the conceptual status of self-report and objective sleep quality is clearer.

<!-- Generally, self-report and objective measures of sleep quality do not cohere well @kaplan2017 -->
<!-- As stated by @krystal2008quality "it seems unlikely that such a global rating would be consistently related to a single physiological aspect of sleep".  -->
<!-- Sleep efficiency (SE), the most common objective sleep quality component identified in this review, is unlikely to -->
<!-- Studies by @harvey2008subjective and @libman2016 found that self-report sleep quality in both healthy adults and those experiencing insomnia was typically defined by feelings and mood upon waking, consolidation and continuity of sleep, and daytime functioning.  -->
<!-- Sleep continuity discrepancy could be a good candidate -->
<!-- comparing holistic measures of sleep quality e.g., PSQI not appropriate to compare with nightly objective sleep -->
<!-- Sleep questionnaires such as the PSQI that provide a more global measure of sleep quality -->

## Sleep diaries should not be used to define rest intervals in sleep discrepancy research {#actidiary}

Sleep diaries were the most commonly identified method of rest interval definition in this review. Sleep diaries were classified by this review as a self-report measure of sleep. By using sleep diaries to define actigraphic rest intervals, self-report sleep is being used to partially define an objective sleep measure. In this case, the measured discrepancy between the two forms of sleep measurement will not be an accurate representation of their actual incongruence. The high frequency at which sleep diaries are back-filled or misreported [@clegg2023real] highlights the significance of this issue. We noted that a single study in the present review addressed this problem directly. Krahn et al [@krahn_assessing_1997] ensured that manual scorers of the rest intervals for their actigraphy data were blinded to the sleep diary. It may be helpful for further research that alternatives such as these are sought for defining rest interval periods.

## The scope of sleep discrepancy research is likely to have been underestimated

The scope of the literature on sleep discrepancy has been considerably underestimated to date. We intended to identify a broad range of studies in this review that may have captured the concept of sleep discrepancy without necessarily referring to this or related terms. A search across full texts of all studies included in this review returned `r (grepl("discrepancy", screen$abstract, ignore.case = TRUE) & grepl("sleep", screen$abstract, ignore.case = TRUE)) %>% sum()` records making explicit mention of "sleep" and "discrepancy", leaving `r nrow(screen) - (grepl("discrepancy", screen$abstract, ignore.case = TRUE) & grepl("sleep", screen$abstract, ignore.case = TRUE)) %>% sum()` that would have otherwise been unidentifiable through simple keyword searching of this concept. A prior review of paradoxical insomnia and subjective-objective sleep discrepancy [@Rezaie2018] identified a total of 40 records. Although conducted four years prior, this review used broader inclusion criteria extending to paradoxical insomnia, the parameters for which do not typically involve direct comparisons of self-report and objective sleep. A corollary to this underestimation of breadth is that existing sleep discrepancy research across domains may be excessively siloed into respective research areas. Looking at the clinical populations encompassed in this review, there appear to be small but distinguishable sleep discrepancy research programmes in post-traumatic stress disorder, bipolar disorder, pregnancy, traumatic brain injury, and fibromyalgia, to name just a few. Whilst sleep discrepancy is best understood in the context of insomnia, it is possible similar processes underlie the presence of sleep discrepancy in these groups. For example, the role of sleep disturbance as a transdiagnostic factor across psychiatric disorders has been emphasised [@harvey2011sleep] and a mechanistic role for sleep misperception has been suggested for disorders outside of insomnia [@richardson2016].

## Strengths and limitations {#item20}

This study represents the largest systematic approach to investigating methodology in the area of sleep discrepancy research. We reported a broad range of methodological features across a large number of studies and provided meaningful syntheses of research methods in a diverse field. Two major changes were made to our own methods during the screening process and following registration of the scoping review protocol that may be viewed as limitations. These changes were both made in response to the unanticipated number of records returned following title and abstract screening and in view of limited resources available for charting and synthesis. First, grey literature was removed from inclusion criteria. Although the issues and recommendations discussed in this paper were limited to published research, our findings remain broadly applicable and no syntheses of empirical findings have been made that could be influenced by publication bias. Second, reference lists were not screened for additional studies and the extent to which this review may be considered an exhaustive representation of the literature may be reduced as a result.

## Summary {#item21}

Methods for investigating sleep discrepancy have varied considerably in the literature across the areas of study design, measurement, data processing, and data analysis. Many of these varied approaches have substantial effects on what sleep discrepancy means as a concept and sometimes are associated with methodological problems that may not be immediately clear. Sleep discrepancy research holds promise for advancing understanding of sleep, its disorders such as insomnia, and mechanisms at play in psychiatric and other disorders. Clear concepts and appropriate methodology is essential to ensure that work in this area remains a progressive science. Measuring discrepancy or congruence is often a deceptively complex undertaking and we hope that this scoping review will prove helpful and informative to those interested in designing or interpreting sleep discrepancy studies.

# Data availability statement

All code and data underlying this article are available from github: https://github.com/tfwalton/sleep-discrepancy-review.

# Acknowledgements

We would like to thank the librarians at the University of Western Australia library for their assistance with the development of the search strategy.

# Financial disclosure statement

None.

# Funding {#item22}

This work forms part of PhD project funded by the Australian Government Research Training Program.

# Declaration of competing interest

The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.

# Appendices

## Search strategies

Search strategies for databases searched using the Ovid system are available in Table \@ref(tab:ovid). Search strategies for other databases are listed in Table \@ref(tab:databases).

``` {r ovid, echo = FALSE, warning = FALSE, message = FALSE}
col1 <- c(seq(1:7), seq(1:7), seq(1:7))
col2 <- c('sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actimetry/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6',
          'sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actigraphy/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6',
          'sleep discrepancy or paradoxical insomnia or subjective insomnia or (sleep adj2 misperception).mp',
          '((self report* or diary or subjective*) and (objective* or actigraph* or polysomnograph* or polygraph*)).mp.',
          '(exp polysomnography/ or exp actigraphy/) and exp self report/ ',
          '(sleep* and ("over estimat*" or "over report*" or "under estimat*" or "under report*" or overestimat* or overreport* or underestimat* or underreport* or discrepan* or concordan* or agreement or disagreement or discordan* or congruen* or incongruen*)).mp.',
          '2 or 3',
          '4 and 5',
          '1 or 6'
)
col3 <- c(488, 193243, 1676, 9362, 193302, 1234, 1569, 175, 57592, 59, 2112, 57592, 346, 471, 260, 139088, 561, 5280, 139088, 692, 875)
df <- data.frame("step" = col1, "terms" = col2, "records" = col3)
colnames(df) <- c("Step", "Terms and operators", "Records")

kable(df,
      format = "latex",
      caption = "Search strategy for Ovid databases"
) %>%
  kable_styling(font_size = 10, full_width = FALSE) %>%
  pack_rows("Embase", 1,7) %>%
  pack_rows("PsycINFO", 8,14) %>%
  pack_rows("Medline", 15,21)

```

``` {r databases, echo = FALSE, warning = FALSE, message = FALSE}

col1 <- c(
'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*)) OR (("Polysomnography/methods"[MAJR] OR "Actigraphy/methods"[MAJR]) AND "Self Report"[MeSH])
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'TITLE-ABS-KEY ( ( "sleep discrepancy"  OR  "paradoxical insomnia"  OR  "subjective insomnia" )  OR  ( sleep  AND  misperception )  OR  ( ( "self report*"  OR  diary  OR  subjective* )  AND  ( objective*  OR  actigraph*  OR  polysomnograph*  OR  polygraph* ) )  AND  ( sleep*  AND  ( "over estimat*"  OR  "over report*"  OR  "under estimat*"  OR  "under report*"  OR  overestimat*  OR  overreport*  OR  underestimat*  OR  underreport*  OR  discrepan*  OR  concordan*  OR  agreement  OR  disagreement  OR  discordan*  OR  congruen*  OR  incongruen* ) ) ) ',

'("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
(("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport* OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))',

'noft(("sleep discrepancy" OR "paradoxical insomnia" OR "subjective insomnia") OR (sleep AND misperception) OR
((("self report*" or diary or subjective*) AND (objective* or actigraph* or polysomnograph* or polygraph*))
AND (sleep* AND ("over estimat*" OR "over report*" OR "under estimat*" OR "under report*" OR overestimat* OR overreport* OR underestimat* OR underreport*
OR discrepan* OR concordan* OR agreement OR disagreement OR discordan* OR congruen* OR incongruen*))))'
)

col2 <- c(761, 310, 826, 1288, 90)
df <- data.frame("terms" = col1, "records" = col2)
colnames(df) <- c("Terms and operators", "Records")

kable(df,
      format = "latex",
      booktabs = TRUE,
      caption = "Search strategy for other databases"
      ) %>%
  kable_styling(font_size = 10, full_width = FALSE) %>%
  column_spec(1, width = "15cm")
#   pack_rows("Pubmed", 1,1) %>%
#   pack_rows("CINAHL Plus", 2,2) %>%
#   pack_rows("Scopus", 3,3) %>%
#   pack_rows("Web of Science", 4,4) %>%
#   pack_rows("Proquest Theses and Dissertations Global", 5,5)

```

## List of deviations from protocol {#deviations}

The following are a list of deviations from the scoping review protocol registered on the Open Science Framework (doi: 10.17605/OSF.IO/BCJNQ).

1. The term actimetry in Medline and PSYCinfo searches was changed to actigraphy
2. The scoping review protocol listed an incorrect number of duplicates records following searches
3. All records that were not peer reviewed journal articles were excluded at the full-text screening stage in the final review
4. Other items were added to the exclusion criteria at the full-text screening stage including:
 + study measured informant-report rather than strictly self-report sleep
 + study did not include statistical comparison of self-report and objective sleep (e.g., numerical comparisons only, single-case design)
5. Reference lists were not searched for additional citations as planned in the protocol

## PRISMA-ScR checklist

``` {r checklist, echo = FALSE, warning = FALSE, message = FALSE}

col1 <- c(
  "Title", "Structured summary", "Rationale", "Objectives", "Protocol and registrations", "Eligibility criteria", "Information sources", "Search", "Selection of sources of evidence", "Data charting process", "Data items", "Critical appraisal of individual sources of evidence", "Synthesis of results", "Selection of sources of evidence", "Characteristics of sources of evidence", "Critical appraisal within sources of evidence", "Results of individual sources of evidence", "Synthesis of results", "Summary of evidence", "Limitations", "Conclusions", "Funding"
)

col2 <- seq(1:22)

col3 <- c(
  "Identify the report as a scoping review.",
  "Provide a structure summary that includes (as applicable): background, objectives, eligibility criteria, sources of evidence, charting methods, results, and conclusions that relate to the review questions and objectives.",
  "Describe the rationale for the review in the context of what is already known. Explain why the review questions/ objectives lend themselves to a scoping review approach",
  "Provide an explicit statement of the questions and objectives being addressed with reference to their key elements (e.g., population or participants, concepts, and context) or other relevant key elements used to conceptualise the review questions and/or objectives.",
  "Indicate whether a review protocol exists; state if and where it can be accessed (e.g., a Web address); and if available, provide registration information, including the registration number.",
  "Specify characteristics of the sources of evidence used as eligibility criteria (e.g., years considered, language, and publication status), and provide a rationale.",
  "Describe all information sources in the search (e.g., databases with dates of coverage and contact with authors to identify additional sources), as well as the date the most recent search was executed.",
  "Present the full electronic search strategy for at least 1 database, including any limits used, such that it could be repeated.",
"State the process for selecting sources of evidence (i.e., screening and eligibility) included in the scoping review.",
"Describe the methods of charting data from the included sources of evidence (e.g., calibrated forms or forms that have been tested by the team before their use, and whether data charting was done independently or in duplicate) and any processes for obtaining and confirming data from investigators.",
"List and define all variables for which data were sought and any assumptions and simplifications made",
"If done, provide a rationale for conducting a critical appraisal of included sources of evidence; describe the methods used and how this information was used in any data synthesis (if appropriate).",
"Describe the methods of handling and summarizing the data that were charted",
"Give numbers of sources of evidence screen, assessed for eligibility, and included in the review, with reasons for exclusions at each stage, ideally using a flow diagram.",
"For each source of evidence, present characteristics for which data were charted and provide the citations.",
"If done, present data on critical appraisal of included sources of evidence (see item 12).",
"For each included source of evidence, present the relevant data that were charted that relate to the review questions and objectives.",
"Summarize and/or present the charting results as they relate to the review questions and objectives.",
"Summarize the main results (including an overview of concepts, themes, and types of evidence available), link to the review questions and objectives, and consider the relevance to key groups",
"Discuss the limitations of the scoping review process.",
"Provide a general interpretation of the results with respect to the review questions and objectives, as well as potential implications and/or next steps.",
"Describe sources of funding for the included sources of evidence, as well as sources of funding for the scoping review. Describe the role of the funders of the scoping review."
)

# Double backslash so rmarkdown doesn't read it as an escape

col4 <- c("\\@ref(abstract)", #item1
          "\\@ref(abstract)", #item2
          "\\@ref(introduction)", #item3
          "\\@ref(introduction)", #item4
          "\\@ref(protocol)", #item5
          "\\@ref(item6)",
          "\\@ref(item7)",
          "\\@ref(tab:egsearch)", #item8
          "\\@ref(item9)",
          "\\@ref(item10)",
          "\\@ref(item11)",
          "Formal quality assessment was not conducted", #item12
          "\\@ref(item13)",
          "\\@ref(item14)",
          "\\@ref(tab:studychar)", #item 15
          "Formal quality assessment was not conducted", #item16
          "\\@ref(resultsandsynthesis)", #item17
          "\\@ref(resultsandsynthesis)", #item18
          "\\@ref(item19)",
          "\\@ref(item20)",
          "\\@ref(item21)",
          "\\@ref(item22)"
          )

df <- data.frame("section" = col1, "item_no" = col2, "item" = col3, "page" = col4)
colnames(df) <- c("Section", "Item", "PRISMA-ScR Checklist Item", "Location reported")

kable(df,
      format = "latex",
      caption = "Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) Checklist."
) %>%
  kable_styling(font_size = 10, full_width = FALSE) %>%
  pack_rows("Title", 1,1) %>%
  pack_rows("Abstract", 2,2) %>%
  pack_rows("Introduction", 3,4) %>%
  pack_rows("Methods", 5, 13) %>%
  pack_rows("Results", 14, 18) %>%
  pack_rows("Discussion", 19, 21) %>%
  pack_rows("Funding", 22, 22)


```
## Additional tables

Full descriptions of study characteristics are available in Table \@ref(tab:studychar).

``` {r studychar, echo = FALSE, warning = FALSE, message = FALSE}
df <- subset(screen, select = c(ama_cite, bibkey_ama, country, country2,
                                sample_characteristics,
                                sample_size))

# Concatenate country and country2 columns
df$country <- ifelse(df$country2 != "", paste(df$country, df$country2, sep = ", "),
                     df$country)

# Remove country2
df <- df[ ,-4]

# add citations for each study
df$ama_cite <- paste0(df$ama_cite, df$bibkey_ama)

# remove bibkey column
df <- df[,-2]

# capitalise first letter of sample characteristics column
df$sample_characteristics <- paste0(toupper(substring(df$sample_characteristics,1,1)), substring(df$sample_characteristics,2,last = 1000L))

# change column names
colnames(df) <- c("Study", "Country of origin", "Sample characteristics", "Sample size")

# reorder rows
df <- arrange(df, Study)

kable(df, format = "latex", caption = "Characteristics of included studies") %>%
  kable_styling(font_size = 10, full_width = FALSE)
```

Full qualitative methodological details for actigraphy studies are available in Table \@ref(tab:bigacti).

``` {r bigacti, echo = FALSE, warning = FALSE, message = FALSE}

df <- subset(screen, select = c(ama_cite,
                                bibkey_ama,
                                obj_movement,
                                acti_device,
                                acti_device2,
                                acti_device3,
                                acti_software_short,
                                acti_algorithm,
                                acti_algorithm2,
                                acti_algorithm3,
                                acti_interval_description))

df$acti_device2 <- ifelse(df$acti_device3 != "", paste(df$acti_device2, df$acti_device3, sep = ", "),
                                                    df$acti_device2)

df$acti_device <- ifelse(df$acti_device2 != "", paste(df$acti_device, df$acti_device2, sep = ", "),
                         df$acti_device)


collapseActiware <- function(x) {
  ifelse(grepl("Actiware", x), "Actiware", x)
}

# Apply function to data frame
df$algo_ref1 <- sapply(df$acti_algorithm, collapseActiware)
df$algo_ref2 <- sapply(df$acti_algorithm2, collapseActiware)
df$algo_ref3 <- sapply(df$acti_algorithm3, collapseActiware)

# Replace names with algorithm bibliography keys
algo_citations <- read.csv("../data/algorithm_citations.csv")

# Search the table for a citation that matches the algorithm and paste it into each cell
for (x in df[ ,12]) {
  i <- which(df[ ,12] == x)
  ref <- which(algo_citations[ ,1] == x)
  df[i,12] <- paste0(algo_citations[ref,3], "")
}

# Search the table for a citation that matches the algorithm and paste it into each cell
for (x in df[ ,13]) {
  i <- which(df[ ,13] == x)
  ref <- which(algo_citations[ ,1] == x)
  df[i,13] <- paste0(algo_citations[ref,3], "")
}

# Search the table for a citation that matches the algorithm and paste it into each cell
for (x in df[ ,14]) {
  i <- which(df[ ,14] == x)
  ref <- which(algo_citations[ ,1] == x)
  df[i,14] <- paste0(algo_citations[ref,3], "")
}

df$acti_algorithm2 <- ifelse(df$acti_algorithm3 != "", paste(df$acti_algorithm2, df$acti_algorithm3, sep = ", "),
                          df$acti_algorithm2)

df$acti_algorithm <- ifelse(df$acti_algorithm2 != "", paste(df$acti_algorithm, df$acti_algorithm2, sep = ", "),
                         df$acti_algorithm)


df$algo_ref2 <- ifelse(df$algo_ref3 != "", paste(df$algo_ref2, df$algo_ref3, sep = "^;^ "),
                             df$algo_ref2)

df$algo_ref1 <- ifelse(df$algo_ref2 != "", paste(df$algo_ref1, df$algo_ref2, sep = "^;^ "),
                            df$algo_ref1)

# Collapse citation column with study column
df$ama_cite <- paste(df$ama_cite, df$bibkey_ama)
df <- df[,-2]

# keep actigraphy studies
df <- df[which(df$obj_movement == 1), ]

# remove surplus columns
df <- df[ , -c(2, 4,5, 8, 9, 12, 13)]

# move the algorithm references after the algorithm column
df <- df %>% relocate(algo_ref1, .after = acti_algorithm)

# capitalise first letter of rest interval column
df$acti_interval_description <- paste0(toupper(substring(df$acti_interval_description,1,1)), substring(df$acti_interval_description,2,last = 1000L))

colnames(df) <- c("Study", "Actigraph device", "Software", "Algorithm", "Algorithm reference", "Rest interval definition")

kable(df, format = "latex", caption = "Qualitative actigraphy characteristics") %>%
  kable_styling(font_size = 10, full_width = FALSE) %>% 
  footnote(footnote_as_chunk = TRUE, general = "The --> arrow designates the priority given to methods of calculating the rest interval. For example, event markers –> activity, sleep diary, indicates that event marker presses were first used to calculate rest intervals, followed by sleep diary and activity when event marker presses were not available.")

```

A full list of studies that recorded sleep-wake agreement is available in Table \@ref(tab:sleepwake) below.

``` {r sleepwake, echo = FALSE, warning = FALSE, message = FALSE}

# create dataframe of relevant variables
df <- subset(screen, binary_sw_I == 1 | binary_sw_II == 1, select = c(ama_cite,
                                                                      bibkey_ama,
                                                                      sample_characteristics,
                                                                      binary_sw_I,
                                                                      binary_sw_II,
                                                                      sleepvar_list,
                                                                      psg_setting
                                ))

# recoding the two sleep-wake variables (they were mutually exclusive)
df$sleep_wake <- ifelse(df$binary_sw_I %>% is.na(), "Confusion matrix", "Binary")

# collapse bibkey column with study column
df$ama_cite <- paste(df$ama_cite, df$bibkey_ama)

# remove bibkey column
df <- df[ ,-2]

# remove binary_sw columns
df <- df[ ,-c(3,4)]

df <- df %>% relocate(sleep_wake, .after = sleepvar_list)

colnames(df) <- c("Study", "Sample characteristics", "Sleep variables", "Sleep-wake agreement type", "PSG setting")

kable(df, format = "latex", caption = "Direct sleep-wake agreement studies") %>%
  kable_styling(font_size = 10, full_width = FALSE) %>% 
  footnote(footnote_as_chunk = TRUE, general = "Binary sleep-wake involved measuring at one or multiple instances whether a participant's reported sleep state matched the objective sleep state upon which the query was conditional (e.g., participants were only queried during objectively-confirmed sleep). On the other hand, confusion matrix sleep-wake involved measuring at one or multiple instances whether a participant's reported sleep state matched an objective sleep state that was allowed to vary independent of the query (e.g., participants were queried at a certain time point irrespective of sleep state). The states were called so as the former approach produces a binary outcome whereas the latter produces a confusion matrix.")
```

# References
